import streamlit as st
import pandas as pd
import numpy as np
import io
import time
import warnings
from datetime import datetime, timedelta
from collections import deque
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
import json

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------------------------------------
# 1. æ ¸å¿ƒåŒ¹é…å¼•æ“ (æ ¹æ®æ–°éœ€æ±‚æ›´æ–°)
# ---------------------------------------------------------

class HedgeMatchingEngine:
    """å¥—ä¿åŒ¹é…å¼•æ“ - æ›´æ–°ç‰ˆ"""
    
    def __init__(self):
        self.df_paper = None
        self.df_physical = None
        self.df_paper_net = None
        self.df_relations = None
        self.df_physical_updated = None
        self.open_positions_summary = None  # å¼€ä»“æ±‡æ€»
        self.close_positions_summary = None  # å¹³ä»“æ±‡æ€»
        
    def clean_str(self, series):
        """æ¸…æ´—å­—ç¬¦ä¸² - å¤„ç†NaNå’Œfloatå€¼"""
        if series.empty:
            return pd.Series([], dtype=str)
            
        # å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œå¤„ç†NaN
        series = series.copy()
        series = series.fillna('')
        
        # å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        def safe_str(x):
            if isinstance(x, (int, float)):
                return str(x)
            return str(x)
        
        series = series.apply(safe_str)
        return series.str.strip().str.upper().replace('NAN', '').replace('NONE', '')
    
    def standardize_month(self, series):
        """æ ‡å‡†åŒ–æœˆä»½æ ¼å¼ - å¢å¼ºé”™è¯¯å¤„ç†"""
        if series.empty:
            return pd.Series([], dtype=str)
            
        s = series.copy()
        s = s.fillna('')
        
        # å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        def safe_str(x):
            if isinstance(x, (int, float)):
                return str(x)
            return str(x)
        
        s = s.apply(safe_str)
        s = s.str.strip().str.upper()
        s = s.str.replace('-', ' ', regex=False).str.replace('/', ' ', regex=False)
        dates = pd.to_datetime(s, errors='coerce', format='mixed')
        result = dates.dt.strftime('%b %y').str.upper()
        mask_invalid = dates.isna()
        
        if mask_invalid.any():
            invalid = s[mask_invalid]
            def swap_if_match(val):
                if not isinstance(val, str):
                    return val
                m = re.match(r'^(\d{2})\s*([A-Z]{3})$', val)
                if m:
                    yr, mon = m.groups()
                    return f"{mon} {yr}"
                return val
            swapped = invalid.apply(swap_if_match)
            swapped_dates = pd.to_datetime(swapped, errors='coerce')
            swapped_formatted = swapped_dates.dt.strftime('%b %y').str.upper()
            result.loc[mask_invalid & swapped_dates.notna()] = swapped_formatted.loc[swapped_dates.notna()]
            result.loc[mask_invalid & swapped_dates.isna()] = swapped.loc[swapped_dates.isna()]
        
        # å¡«å……ç©ºå€¼
        result = result.fillna('')
        return result
    
    def safe_upper(self, value):
        """å®‰å…¨çš„å­—ç¬¦ä¸²å¤§å†™è½¬æ¢"""
        if pd.isna(value) or value is None:
            return ''
        if isinstance(value, (int, float)):
            return str(value).upper()
        return str(value).upper()
    
    def get_physical_priority(self, cargo_id):
        """è·å–å®è´§åŒ¹é…ä¼˜å…ˆçº§ - å¢å¼ºé”™è¯¯å¤„ç†"""
        if pd.isna(cargo_id) or cargo_id is None:
            return 100
            
        # å®‰å…¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        cargo_id_str = self.safe_upper(str(cargo_id))
        
        # æŒ‰ç…§ä½ çš„è¦æ±‚ï¼šphy-2026-04 -> phy-2026-05 -> phy-2026-01 -> phy-2026-02 -> phy-2026-03
        priority_map = {
            'PHY-2026-04': 1,
            'PHY-2026-05': 2,
            'PHY-2026-01': 3,
            'PHY-2026-02': 4,
            'PHY-2026-03': 5
        }
        
        # åŒ¹é… cargo_id ä¸­çš„å…³é”®éƒ¨åˆ†
        for key in priority_map:
            if key in cargo_id_str:
                return priority_map[key]
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
        return 100
    
    def get_commodity_priority(self, commodity):
        """è·å–å•†å“ä¼˜å…ˆçº§ï¼šBRENTä¼˜å…ˆï¼ŒJCCæ¬¡ä¹‹"""
        if pd.isna(commodity) or commodity is None:
            return 3
            
        commodity_str = self.safe_upper(str(commodity))
        if 'BRENT' in commodity_str:
            return 1
        elif 'JCC' in commodity_str:
            return 2
        else:
            return 3
    
    def calculate_net_positions(self, df_paper, designation_date):
        """FIFOå‡€ä»“è®¡ç®— - è¿‡æ»¤æŒ‡å®šæ—¥æœŸå‰çš„äº¤æ˜“"""
        st.info("ğŸ”„ æ‰§è¡Œçº¸è´§å†…éƒ¨å¯¹å†² (FIFO Netting)...")
        progress_bar = st.progress(0)
        
        # è¿‡æ»¤æŒ‡å®šæ—¥æœŸä¹‹å‰çš„äº¤æ˜“ï¼ˆä¸å‚ä¸åŒ¹é…ï¼‰
        df_paper_filtered = df_paper.copy()
        
        # ç¡®ä¿Trade Dateæ˜¯datetimeç±»å‹
        if 'Trade Date' in df_paper_filtered.columns:
            df_paper_filtered['Trade Date'] = pd.to_datetime(df_paper_filtered['Trade Date'], errors='coerce')
        
        if designation_date and 'Trade Date' in df_paper_filtered.columns:
            designation_dt = pd.to_datetime(designation_date)
            before_mask = df_paper_filtered['Trade Date'] < designation_dt
            if before_mask.any():
                st.warning(f"è¿‡æ»¤æ‰ {before_mask.sum()} æ¡æŒ‡å®šæ—¥æœŸ({designation_date})ä¹‹å‰çš„çº¸è´§äº¤æ˜“")
                df_paper_filtered = df_paper_filtered[~before_mask].copy()
        
        if df_paper_filtered.empty:
            st.error("æŒ‡å®šæ—¥æœŸä¹‹åæ²¡æœ‰å¯ç”¨çš„çº¸è´§äº¤æ˜“æ•°æ®")
            return pd.DataFrame()
        
        df_paper_filtered = df_paper_filtered.sort_values(by='Trade Date').reset_index(drop=True)
        df_paper_filtered['Group_Key'] = df_paper_filtered['Std_Commodity'] + "_" + df_paper_filtered['Month']
        
        # åˆ›å»ºå‰¯æœ¬ï¼Œé¿å…åœ¨è¿­ä»£ä¸­ä¿®æ”¹åŸå§‹è®°å½•çš„é—®é¢˜
        records = []
        for idx, row in df_paper_filtered.iterrows():
            record = row.to_dict()
            # ç¡®ä¿Close_Eventsæ˜¯åˆ—è¡¨
            record['Close_Events'] = []
            records.append(record)
        
        groups = {}
        
        # åˆ†ç»„
        for i, row in enumerate(records):
            key = row['Group_Key']
            if key not in groups:
                groups[key] = []
            groups[key].append(i)
            if i % 100 == 0:
                progress_bar.progress(min(i / len(records) * 0.5, 0.5))
        
        # FIFOå‡€é¢åŒ–
        group_count = 0
        total_groups = len(groups)
        for key, indices in groups.items():
            open_queue = deque()
            for idx in indices:
                row = records[idx]
                current_vol = row.get('Volume', 0)
                records[idx]['Net_Open_Vol'] = current_vol
                records[idx]['Closed_Vol'] = 0
                
                if abs(current_vol) < 0.0001:
                    continue
                
                current_sign = 1 if current_vol > 0 else -1
                
                # å°è¯•ä¸é˜Ÿåˆ—ä¸­çš„äº¤æ˜“æŠµæ¶ˆ
                while open_queue:
                    q_idx, q_vol, q_sign = open_queue[0]
                    if q_sign != current_sign:  # æ–¹å‘ç›¸åæ‰èƒ½æŠµæ¶ˆ
                        offset = min(abs(current_vol), abs(q_vol))
                        current_vol -= (current_sign * offset)
                        q_vol -= (q_sign * offset)
                        
                        # è®°å½•å¹³ä»“äº‹ä»¶
                        close_event = {
                            'Ref': str(records[idx].get('Recap No', '')),
                            'Date': records[idx].get('Trade Date'),
                            'Vol': offset,
                            'Price': records[idx].get('Price', 0),
                            'Commodity': records[idx].get('Std_Commodity'),
                            'Month': records[idx].get('Month')
                        }
                        records[q_idx]['Close_Events'].append(close_event)
                        records[q_idx]['Closed_Vol'] += offset
                        records[q_idx]['Net_Open_Vol'] = q_vol
                        records[idx]['Closed_Vol'] += offset
                        records[idx]['Net_Open_Vol'] = current_vol
                        
                        if abs(q_vol) < 0.0001:
                            open_queue.popleft()
                        else:
                            open_queue[0] = (q_idx, q_vol, q_sign)
                        
                        if abs(current_vol) < 0.0001:
                            break
                    else:
                        break
                
                # å‰©ä½™éƒ¨åˆ†å…¥é˜Ÿ
                if abs(current_vol) > 0.0001:
                    open_queue.append((idx, current_vol, current_sign))
            
            group_count += 1
            progress_bar.progress(0.5 + (group_count / total_groups) * 0.5)
        
        progress_bar.progress(1.0)
        st.success(f"âœ… çº¸è´§å†…éƒ¨å¯¹å†²å®Œæˆï¼å…±å¤„ç† {len(groups)} ä¸ªå•†å“-æœˆä»½ç»„åˆ")
        return pd.DataFrame(records)
    
    def prepare_dataframe_for_operations(self, df):
        """å‡†å¤‡æ•°æ®æ¡†ç”¨äºæ“ä½œï¼Œç¡®ä¿æ²¡æœ‰ä¸å¯å“ˆå¸Œçš„ç±»å‹"""
        df_copy = df.copy()
        
        # å°†Close_Eventsåˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²è¡¨ç¤ºï¼Œä»¥ä¾¿å»é‡æ“ä½œ
        if 'Close_Events' in df_copy.columns:
            df_copy['Close_Events_Str'] = df_copy['Close_Events'].apply(
                lambda x: json.dumps(x) if isinstance(x, list) else str(x)
            )
            # åˆ›å»ºä¸€ä¸ªä¸å¸¦Close_Eventsåˆ—çš„æ•°æ®æ¡†ç”¨äºå»é‡
            df_for_ops = df_copy.drop(columns=['Close_Events'])
        else:
            df_for_ops = df_copy
        
        return df_for_ops
    
    def match_hedges(self, df_physical, df_paper_net, designation_date):
        """å®è´§åŒ¹é… - æ ¹æ®æ–°éœ€æ±‚æ›´æ–°"""
        st.info("ğŸ”„ å¼€å§‹å®è´§åŒ¹é…...")
        progress_bar = st.progress(0)
        
        hedge_relations = []
        open_positions = []  # è®°å½•å¼€ä»“å¤´å¯¸
        close_positions = []  # è®°å½•å¹³ä»“å¤´å¯¸
        
        # å‡†å¤‡çº¸è´§æ•°æ®ç”¨äºæ“ä½œ
        active_paper = df_paper_net.copy()
        active_paper['Allocated_To_Phy'] = 0.0
        active_paper['_original_index'] = active_paper.index
        
        df_phy = df_physical.copy()
        df_phy['_orig_idx'] = df_phy.index
        
        # æ•°æ®æ¸…æ´—å’ŒéªŒè¯
        st.info("ğŸ”„ æ•°æ®æ¸…æ´—å’ŒéªŒè¯ä¸­...")
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        required_fields = ['Cargo_ID', 'Unhedged_Volume']
        for field in required_fields:
            if field not in df_phy.columns:
                st.error(f"å®è´§æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                return pd.DataFrame(), df_physical
        
        # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
        df_phy['Cargo_ID'] = df_phy['Cargo_ID'].apply(lambda x: '' if pd.isna(x) else str(x))
        df_phy['Unhedged_Volume'] = pd.to_numeric(df_phy['Unhedged_Volume'], errors='coerce').fillna(0)
        
        if 'Hedge_Proxy' in df_phy.columns:
            df_phy['Hedge_Proxy'] = df_phy['Hedge_Proxy'].apply(lambda x: '' if pd.isna(x) else str(x))
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºå®è´§
        # 1. å•†å“ä¼˜å…ˆçº§ï¼šBRENTä¼˜å…ˆ
        # 2. Cargo_IDä¼˜å…ˆçº§ï¼šphy-2026-04 -> 05 -> 01 -> 02 -> 03
        # 3. æŒ‰åŸç´¢å¼•ä½œä¸ºæœ€åæ’åºä¾æ®
        
        if 'Hedge_Proxy' in df_phy.columns:
            df_phy['_commodity_priority'] = df_phy['Hedge_Proxy'].apply(self.get_commodity_priority)
        else:
            df_phy['_commodity_priority'] = 3
        
        if 'Cargo_ID' in df_phy.columns:
            df_phy['_cargo_priority'] = df_phy['Cargo_ID'].apply(self.get_physical_priority)
        else:
            df_phy['_cargo_priority'] = 100
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        df_phy = df_phy.sort_values(
            by=['_commodity_priority', '_cargo_priority', '_orig_idx']
        ).reset_index(drop=True)
        
        # ç§»é™¤ä¸´æ—¶åˆ—
        df_phy = df_phy.drop(columns=['_commodity_priority', '_cargo_priority'])
        
        total_cargos = len(df_phy)
        
        for idx, (_, cargo) in enumerate(df_phy.iterrows()):
            cargo_id = str(cargo.get('Cargo_ID', ''))
            phy_vol = float(cargo.get('Unhedged_Volume', 0))
            
            if abs(phy_vol) < 0.0001:
                continue
            
            proxy = str(cargo.get('Hedge_Proxy', ''))
            target_month = cargo.get('Target_Contract_Month', '')
            phy_dir = cargo.get('Direction', 'Buy')
            desig_date = cargo.get('Designation_Date', pd.NaT)
            
            # ç­›é€‰å€™é€‰äº¤æ˜“ - ä¼˜å…ˆåŒ¹é…ç›¸åŒå“ç§å’Œæœˆä»½
            candidates_df = active_paper.copy()
            
            # å®‰å…¨å¤„ç†å­—ç¬¦ä¸²åŒ¹é…
            if proxy:
                mask = candidates_df['Std_Commodity'].apply(
                    lambda x: proxy.upper() in self.safe_upper(x)
                )
                candidates_df = candidates_df[mask].copy()
            
            if not candidates_df.empty and target_month:
                month_mask = candidates_df['Month'].apply(
                    lambda x: str(target_month).upper() == self.safe_upper(str(x))
                )
                candidates_df = candidates_df[month_mask].copy()
            
            # å¦‚æœåŒæœˆä»½ä¸å¤Ÿï¼Œå°è¯•åŒ¹é…å…¶ä»–æœˆä»½çš„ç›¸åŒå“ç§
            if candidates_df.empty or candidates_df['Net_Open_Vol'].abs().sum() < abs(phy_vol):
                # æŸ¥æ‰¾ç›¸åŒå“ç§çš„æ‰€æœ‰äº¤æ˜“
                if proxy:
                    all_same_commodity = active_paper[
                        active_paper['Std_Commodity'].apply(
                            lambda x: proxy.upper() in self.safe_upper(x)
                        )
                    ].copy()
                    
                    if len(all_same_commodity) > 0:
                        # æŒ‰æ—¶é—´æ’åºï¼ˆFIFOï¼‰
                        all_same_commodity = all_same_commodity.sort_values('Trade Date')
                        # ä½¿ç”¨åŸºäºç´¢å¼•çš„åˆå¹¶æ¥é¿å…listç±»å‹é—®é¢˜
                        if not candidates_df.empty:
                            # è·å–å€™é€‰æ•°æ®æ¡†çš„ç´¢å¼•
                            candidates_indices = set(candidates_df.index)
                            all_indices = set(all_same_commodity.index)
                            # åˆå¹¶ç´¢å¼•
                            combined_indices = candidates_indices.union(all_indices)
                            # è·å–åˆå¹¶åçš„æ•°æ®
                            candidates_df = active_paper.loc[list(combined_indices)].copy()
                        else:
                            candidates_df = all_same_commodity
            
            if candidates_df.empty:
                continue
            
            # æ—¶é—´æ’åºï¼šæœ‰æŒ‡å®šæ—¥æœŸæŒ‰æ—¶é—´å·®ï¼Œå¦åˆ™FIFO
            if pd.notna(desig_date) and not candidates_df['Trade Date'].isnull().all():
                candidates_df['Time_Lag_Days'] = (candidates_df['Trade Date'] - desig_date).dt.days
                candidates_df['Abs_Lag'] = candidates_df['Time_Lag_Days'].abs()
                candidates_df = candidates_df.sort_values(by=['Abs_Lag', 'Trade Date'])
            else:
                candidates_df['Time_Lag_Days'] = np.nan
                candidates_df = candidates_df.sort_values(by='Trade Date')
            
            # åˆ†é…åŒ¹é…
            for _, ticket in candidates_df.iterrows():
                if abs(phy_vol) < 1:
                    break
                
                original_index = ticket['_original_index']
                curr_allocated = active_paper.at[original_index, 'Allocated_To_Phy']
                curr_total_vol = float(ticket.get('Volume', 0))
                curr_net_open = float(ticket.get('Net_Open_Vol', 0))
                avail = curr_net_open - curr_allocated
                
                if abs(avail) < 0.0001:
                    continue
                
                # ç¡®å®šåˆ†é…é‡ï¼ˆç¡®ä¿ç¬¦å·æ­£ç¡®ï¼‰
                alloc_amt_abs = abs(phy_vol) if abs(avail) >= abs(phy_vol) else abs(avail)
                # åˆ†é…é‡çš„ç¬¦å·ä¸å¯ç”¨é‡çš„ç¬¦å·ä¸€è‡´
                alloc_amt = np.sign(avail) * alloc_amt_abs
                phy_vol -= alloc_amt_abs if phy_vol > 0 else -alloc_amt_abs
                active_paper.at[original_index, 'Allocated_To_Phy'] += alloc_amt
                
                # è®°å½•å¼€ä»“å’Œå¹³ä»“
                ticket_commodity = str(ticket.get('Std_Commodity', ''))
                ticket_month = str(ticket.get('Month', ''))
                open_price = float(ticket.get('Price', 0))
                
                if alloc_amt > 0:  # å¼€ä»“
                    open_positions.append({
                        'Cargo_ID': cargo_id,
                        'Commodity': ticket_commodity,
                        'Month': ticket_month,
                        'Open_Date': ticket.get('Trade Date'),
                        'Volume': alloc_amt,
                        'Price': open_price,
                        'Ticket_ID': str(ticket.get('Recap No', ''))
                    })
                elif alloc_amt < 0:  # å¹³ä»“
                    close_positions.append({
                        'Cargo_ID': cargo_id,
                        'Commodity': ticket_commodity,
                        'Month': ticket_month,
                        'Close_Date': ticket.get('Trade Date'),
                        'Volume': alloc_amt,  # è´Ÿæ•°
                        'Price': open_price,
                        'Ticket_ID': str(ticket.get('Recap No', ''))
                    })
                
                # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
                mtm_price = float(ticket.get('Mtm Price', open_price))
                total_pl_raw = float(ticket.get('Total P/L', 0))
                close_events = ticket.get('Close_Events', [])
                
                # æ ¼å¼åŒ–å¹³ä»“è·¯å¾„
                close_path_str = ""
                if close_events:
                    sorted_events = sorted(close_events, key=lambda x: x['Date'] if pd.notna(x['Date']) else pd.Timestamp.min)
                    details = []
                    for e in sorted_events:
                        d_str = e['Date'].strftime('%Y-%m-%d') if pd.notna(e['Date']) else 'N/A'
                        p_str = f"@{e['Price']}" if pd.notna(e['Price']) else ""
                        details.append(f"[{d_str} Tkt#{e['Ref']} Vol:{e['Vol']:.0f} {p_str}]")
                    close_path_str = " -> ".join(details)
                
                # è®¡ç®—åˆ†é…æ¯”ä¾‹
                ratio = abs(alloc_amt) / abs(curr_total_vol) if abs(curr_total_vol) > 0 else 0
                unrealized_mtm = (mtm_price - open_price) * alloc_amt
                allocated_total_pl = total_pl_raw * ratio
                
                hedge_relations.append({
                    'Cargo_ID': cargo_id,
                    'Proxy': proxy,
                    'Designation_Date': desig_date,
                    'Open_Date': ticket.get('Trade Date'),
                    'Time_Lag': ticket.get('Time_Lag_Days'),
                    'Ticket_ID': str(ticket.get('Recap No', '')),
                    'Month': ticket_month,
                    'Commodity': ticket_commodity,
                    'Allocated_Vol': alloc_amt,  # æ­£æ•°ä¸ºå¼€ä»“ï¼Œè´Ÿæ•°ä¸ºå¹³ä»“
                    'Trade_Volume': curr_total_vol,
                    'Trade_Net_Open': curr_net_open,
                    'Trade_Closed_Vol': float(ticket.get('Closed_Vol', 0)),
                    'Open_Price': open_price,
                    'MTM_Price': mtm_price,
                    'Alloc_Unrealized_MTM': round(unrealized_mtm, 2),
                    'Alloc_Total_PL': round(allocated_total_pl, 2),
                    'Close_Path_Details': close_path_str,
                    'Position_Type': 'å¼€ä»“' if alloc_amt > 0 else 'å¹³ä»“'
                })
                
                # æ›´æ–°å®è´§æœªå¯¹å†²é‡
                orig_idx = cargo.get('_orig_idx')
                if orig_idx in df_physical.index:
                    df_physical.at[orig_idx, 'Unhedged_Volume'] = phy_vol
            
            progress_bar.progress((idx + 1) / total_cargos)
        
        # æ›´æ–°åˆ†é…é‡
        cols_to_update = active_paper[['_original_index', 'Allocated_To_Phy']].set_index('_original_index')
        df_paper_net.update(cols_to_update)
        
        # è®¡ç®—å¼€ä»“å’Œå¹³ä»“æ±‡æ€»
        if open_positions:
            self.open_positions_summary = self.calculate_weighted_average(open_positions, 'å¼€ä»“')
        else:
            self.open_positions_summary = pd.DataFrame()
            
        if close_positions:
            self.close_positions_summary = self.calculate_weighted_average(close_positions, 'å¹³ä»“')
        else:
            self.close_positions_summary = pd.DataFrame()
        
        progress_bar.progress(1.0)
        df_relations = pd.DataFrame(hedge_relations) if hedge_relations else pd.DataFrame()
        st.success(f"âœ… å®è´§åŒ¹é…å®Œæˆï¼å…±ç”Ÿæˆ {len(df_relations)} æ¡åŒ¹é…è®°å½•")
        
        return df_relations, df_physical
    
    def calculate_weighted_average(self, positions, position_type):
        """è®¡ç®—åŠ æƒå¹³å‡ä»·æ ¼"""
        if not positions:
            return pd.DataFrame()
        
        df = pd.DataFrame(positions)
        
        # ç§»é™¤ç¬¦å·
        if position_type == 'å¹³ä»“':
            df['Volume_Abs'] = abs(df['Volume'])
        else:
            df['Volume_Abs'] = df['Volume']
        
        # ç¡®ä¿æ•°å€¼ç±»å‹
        df['Volume_Abs'] = pd.to_numeric(df['Volume_Abs'], errors='coerce').fillna(0)
        df['Price'] = pd.to_numeric(df['Price'], errors='coerce').fillna(0)
        
        # æŒ‰å•†å“å’Œæœˆä»½åˆ†ç»„è®¡ç®—åŠ æƒå¹³å‡
        summary = df.groupby(['Commodity', 'Month']).apply(
            lambda x: pd.Series({
                'æ€»æ•°é‡': x['Volume_Abs'].sum(),
                'åŠ æƒå¹³å‡ä»·æ ¼': np.average(x['Price'], weights=x['Volume_Abs']) if x['Volume_Abs'].sum() > 0 else 0,
                'äº¤æ˜“æ¬¡æ•°': len(x),
                'æœ€æ—©äº¤æ˜“æ—¥æœŸ': x.iloc[0]['Open_Date'] if position_type == 'å¼€ä»“' else x.iloc[0]['Close_Date'],
                'æœ€æ™šäº¤æ˜“æ—¥æœŸ': x.iloc[-1]['Open_Date'] if position_type == 'å¼€ä»“' else x.iloc[-1]['Close_Date']
            })
        ).reset_index()
        
        summary['å¤´å¯¸ç±»å‹'] = position_type
        return summary
    
    def run_matching(self, df_paper_raw, df_physical_raw, designation_date="2025-11-12"):
        """æ‰§è¡Œå®Œæ•´åŒ¹é…æµç¨‹"""
        try:
            # æ•°æ®é¢„å¤„ç†
            st.info("ğŸ”„ æ•°æ®é¢„å¤„ç†ä¸­...")
            
            # çº¸è´§é¢„å¤„ç†
            df_paper = df_paper_raw.copy()
            
            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
            required_cols_paper = ['Trade Date', 'Volume', 'Commodity']
            for col in required_cols_paper:
                if col not in df_paper.columns:
                    st.error(f"çº¸è´§æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                    return pd.DataFrame(), df_physical_raw, pd.DataFrame(), df_paper, pd.DataFrame(), pd.DataFrame()
            
            # æ ‡å‡†åŒ–å¤„ç†
            df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'], errors='coerce')
            df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
            df_paper['Std_Commodity'] = self.clean_str(df_paper['Commodity'])
            
            if 'Month' in df_paper.columns:
                df_paper['Month'] = self.standardize_month(df_paper['Month'])
            else:
                # å¦‚æœæ²¡æœ‰Monthåˆ—ï¼Œå°è¯•ä»å…¶ä»–åˆ—æ¨æ–­æˆ–åˆ›å»ºé»˜è®¤å€¼
                df_paper['Month'] = df_paper['Trade Date'].dt.strftime('%b %y').str.upper()
            
            # å¤„ç†ç¼ºå¤±å­—æ®µ
            if 'Recap No' not in df_paper.columns:
                df_paper['Recap No'] = [f"TKT-{i+1:04d}" for i in range(len(df_paper))]
            
            for col in ['Price', 'Mtm Price', 'Total P/L']:
                if col not in df_paper.columns:
                    df_paper[col] = 0.0
            
            # å®è´§é¢„å¤„ç†
            df_physical = df_physical_raw.copy()
            
            # æ ‡å‡†åŒ–åˆ—å
            col_mapping = {
                'Target_Pricing_Month': 'Target_Contract_Month',
                'Month': 'Target_Contract_Month',
                'Hedge_Proxy': 'Hedge_Proxy',
                'Direction': 'Direction'
            }
            
            for old_col, new_col in col_mapping.items():
                if old_col in df_physical.columns and new_col not in df_physical.columns:
                    df_physical[new_col] = df_physical[old_col]
            
            # ç¡®ä¿å¿…è¦åˆ—
            if 'Volume' in df_physical.columns:
                df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
                df_physical['Unhedged_Volume'] = df_physical['Volume']
            
            if 'Hedge_Proxy' in df_physical.columns:
                df_physical['Hedge_Proxy'] = self.clean_str(df_physical['Hedge_Proxy'])
            
            if 'Target_Contract_Month' in df_physical.columns:
                df_physical['Target_Contract_Month'] = self.standardize_month(df_physical['Target_Contract_Month'])
            
            # æŒ‡å®šæ—¥æœŸ
            date_cols = ['Designation_Date', 'Pricing_Start', 'Trade Date']
            for col in date_cols:
                if col in df_physical.columns:
                    df_physical['Designation_Date'] = pd.to_datetime(df_physical[col], errors='coerce')
                    break
            else:
                df_physical['Designation_Date'] = pd.NaT
            
            # æ•°æ®éªŒè¯
            st.info("ğŸ”„ æ•°æ®éªŒè¯ä¸­...")
            
            # æ£€æŸ¥å®è´§Cargo_ID
            if 'Cargo_ID' in df_physical.columns:
                df_physical['Cargo_ID'] = df_physical['Cargo_ID'].apply(lambda x: '' if pd.isna(x) else str(x))
                unique_cargos = len(df_physical['Cargo_ID'].unique())
                st.info(f"å®è´§Cargo_IDæ•°é‡: {unique_cargos}")
            
            # æ£€æŸ¥çº¸è´§æ•°æ®
            paper_count = len(df_paper)
            st.info(f"çº¸è´§äº¤æ˜“æ€»æ•°: {paper_count}")
            st.info(f"æŒ‡å®šåŒ¹é…å¼€å§‹æ—¥æœŸ: {designation_date}")
            
            # æ£€æŸ¥æŒ‡å®šæ—¥æœŸä¹‹åçš„äº¤æ˜“
            if 'Trade Date' in df_paper.columns:
                designation_dt = pd.to_datetime(designation_date)
                valid_paper = df_paper[df_paper['Trade Date'] >= designation_dt]
                st.info(f"æŒ‡å®šæ—¥æœŸä¹‹åçš„çº¸è´§äº¤æ˜“æ•°: {len(valid_paper)}")
            
            # æ‰§è¡ŒåŒ¹é…
            self.df_paper_net = self.calculate_net_positions(df_paper, designation_date)
            
            if self.df_paper_net.empty:
                st.warning("çº¸è´§å‡€ä»“æ•°æ®ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®æˆ–è°ƒæ•´æŒ‡å®šæ—¥æœŸ")
                return pd.DataFrame(), df_physical, pd.DataFrame(), df_paper, pd.DataFrame(), pd.DataFrame()
            
            self.df_relations, self.df_physical_updated = self.match_hedges(
                df_physical, self.df_paper_net, designation_date
            )
            
            return (self.df_relations, self.df_physical_updated, 
                    self.df_paper_net, df_paper, 
                    self.open_positions_summary, self.close_positions_summary)
            
        except Exception as e:
            st.error(f"åŒ¹é…è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(e)}")
            st.exception(e)
            return pd.DataFrame(), df_physical_raw, pd.DataFrame(), df_paper_raw, pd.DataFrame(), pd.DataFrame()

# ---------------------------------------------------------
# 2. åˆ†ææ¨¡å— (åŸºäºçœŸå®åŒ¹é…ç»“æœ)
# ---------------------------------------------------------

class HedgeAnalysis:
    """å¥—ä¿åˆ†ææ¨¡å—"""
    
    def __init__(self, df_relations, df_physical, df_paper_net, 
                 open_summary=None, close_summary=None):
        self.df_relations = df_relations if df_relations is not None else pd.DataFrame()
        self.df_physical = df_physical if df_physical is not None else pd.DataFrame()
        self.df_paper_net = df_paper_net if df_paper_net is not None else pd.DataFrame()
        self.open_summary = open_summary if open_summary is not None else pd.DataFrame()
        self.close_summary = close_summary if close_summary is not None else pd.DataFrame()
        self.summary_stats = {}
        self.calculate_summary()
    
    def calculate_summary(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        if self.df_relations.empty:
            self.summary_stats = {
                'total_matched': 0,
                'total_physical': 0,
                'match_rate': 0,
                'open_volume': 0,
                'close_volume': 0,
                'total_pl': 0,
                'total_unrealized': 0,
                'matched_cargos': 0,
                'total_cargos': 0,
                'total_tickets': 0,
                'open_count': 0,
                'close_count': 0,
                'avg_time_lag': 0,
                'std_time_lag': 0
            }
            return
        
        try:
            # åŒ¹é…ç»Ÿè®¡
            if 'Allocated_Vol' in self.df_relations.columns:
                total_matched = abs(self.df_relations['Allocated_Vol']).sum()
            else:
                total_matched = 0
            
            if 'Volume' in self.df_physical.columns:
                total_physical = abs(self.df_physical['Volume']).sum()
            else:
                total_physical = 0
                
            match_rate = (total_matched / total_physical * 100) if total_physical > 0 else 0
            
            # å¼€ä»“å¹³ä»“ç»Ÿè®¡
            if 'Allocated_Vol' in self.df_relations.columns:
                open_positions = self.df_relations[self.df_relations['Allocated_Vol'] > 0]
                close_positions = self.df_relations[self.df_relations['Allocated_Vol'] < 0]
                
                open_volume = open_positions['Allocated_Vol'].sum() if not open_positions.empty else 0
                close_volume = abs(close_positions['Allocated_Vol'].sum()) if not close_positions.empty else 0
            else:
                open_volume = close_volume = 0
            
            # è´¢åŠ¡ç»Ÿè®¡
            total_pl = self.df_relations['Alloc_Total_PL'].sum() if 'Alloc_Total_PL' in self.df_relations.columns else 0
            total_unrealized = self.df_relations['Alloc_Unrealized_MTM'].sum() if 'Alloc_Unrealized_MTM' in self.df_relations.columns else 0
            
            # æ•°é‡ç»Ÿè®¡
            matched_cargos = self.df_relations['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_relations.columns else 0
            total_cargos = self.df_physical['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_physical.columns else 0
            total_tickets = len(self.df_relations)
            
            # æ—¶é—´ç»Ÿè®¡
            if 'Time_Lag' in self.df_relations.columns:
                avg_time_lag = self.df_relations['Time_Lag'].abs().mean()
                std_time_lag = self.df_relations['Time_Lag'].abs().std()
            else:
                avg_time_lag = std_time_lag = 0
            
            self.summary_stats = {
                'total_matched': total_matched,
                'total_physical': total_physical,
                'match_rate': match_rate,
                'open_volume': open_volume,
                'close_volume': close_volume,
                'total_pl': total_pl,
                'total_unrealized': total_unrealized,
                'matched_cargos': matched_cargos,
                'total_cargos': total_cargos,
                'total_tickets': total_tickets,
                'avg_time_lag': avg_time_lag,
                'std_time_lag': std_time_lag
            }
            
        except Exception as e:
            st.warning(f"è®¡ç®—æ±‡æ€»ç»Ÿè®¡æ—¶å‡ºç°é”™è¯¯: {str(e)}")
            self.summary_stats = {
                'total_matched': 0,
                'total_physical': 0,
                'match_rate': 0,
                'open_volume': 0,
                'close_volume': 0,
                'total_pl': 0,
                'total_unrealized': 0,
                'matched_cargos': 0,
                'total_cargos': 0,
                'total_tickets': 0,
                'avg_time_lag': 0,
                'std_time_lag': 0
            }
    
    def create_summary_metrics(self):
        """åˆ›å»ºæ¦‚è§ˆæŒ‡æ ‡å¡ç‰‡"""
        stats = self.summary_stats
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š åŒ¹é…ç‡", f"{stats['match_rate']:.1f}%", 
                     delta=f"{stats['total_matched']:,.0f}/{stats['total_physical']:,.0f}")
        
        with col2:
            coverage = (stats['matched_cargos'] / stats['total_cargos'] * 100) if stats['total_cargos'] > 0 else 0
            st.metric("ğŸ“¦ åŒ¹é…è¦†ç›–ç‡", f"{coverage:.1f}%",
                     delta=f"{stats['matched_cargos']}/{stats['total_cargos']}")
        
        with col3:
            st.metric("ğŸ’° æ€»P/L", f"${stats['total_pl']:,.2f}",
                     delta=f"æœªå®ç°: ${stats['total_unrealized']:,.2f}")
        
        with col4:
            st.metric("âš–ï¸ å¼€ä»“/å¹³ä»“", f"{stats['open_volume']:,.0f}/{stats['close_volume']:,.0f}",
                     delta=f"{stats['matched_cargos']}ä¸ªå®è´§")

# ---------------------------------------------------------
# 3. Streamlit ä¸»åº”ç”¨
# ---------------------------------------------------------

def main():
    st.set_page_config(
        page_title="å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ v2.0",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #374151;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        border-bottom: 2px solid #E5E7EB;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #D1FAE5;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #10B981;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3B82F6;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #FEF3C7;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #F59E0B;
        margin: 1rem 0;
    }
    .error-box {
        background-color: #FEE2E2;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #EF4444;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ“ˆ å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ v2.0</h1>', unsafe_allow_html=True)
    st.markdown("### ä¸“ä¸šå¥—ä¿åŒ¹é…ä¸æœ‰æ•ˆæ€§æµ‹è¯•å·¥å…· | æ”¯æŒåŠ æƒå‡ä»·è®¡ç®—")
    
    # åˆå§‹åŒ–session state
    if 'engine' not in st.session_state:
        st.session_state.engine = HedgeMatchingEngine()
    if 'analysis' not in st.session_state:
        st.session_state.analysis = None
    if 'matching_complete' not in st.session_state:
        st.session_state.matching_complete = False
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        paper_file = st.file_uploader(
            "çº¸è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="paper_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Trade Date, Volume, Commodityç­‰å­—æ®µ"
        )
        
        physical_file = st.file_uploader(
            "å®è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="physical_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Cargo_ID, Volume, Hedge_Proxyç­‰å­—æ®µ"
        )
        
        st.markdown("---")
        st.markdown("### âš™ï¸ åŒ¹é…è®¾ç½®")
        
        # æŒ‡å®šæ—¥æœŸè®¾ç½® - ä¿®æ­£ä¸º2025å¹´
        designation_date = st.date_input(
            "æŒ‡å®šåŒ¹é…å¼€å§‹æ—¥æœŸ",
            value=datetime(2025, 11, 12),  # ä¿®æ­£ä¸º2025å¹´
            help="ä»è¯¥æ—¥æœŸå¼€å§‹çš„çº¸è´§äº¤æ˜“æ‰ä¼šå‚ä¸åŒ¹é…"
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æè®¾ç½®")
        
        show_charts = st.checkbox("æ˜¾ç¤ºåˆ†æå›¾è¡¨", value=True)
        show_positions = st.checkbox("æ˜¾ç¤ºå¤´å¯¸æ±‡æ€»", value=True)
        show_risk = st.checkbox("æ˜¾ç¤ºé£é™©æŒ‡æ ‡", value=False)
        max_rows = st.slider("è¡¨æ ¼æ˜¾ç¤ºè¡Œæ•°", 10, 200, 50)
        
        st.markdown("---")
        
        if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®", type="secondary"):
            st.session_state.engine = HedgeMatchingEngine()
            st.session_state.analysis = None
            st.session_state.matching_complete = False
            st.rerun()
    
    # ä¸»å†…å®¹åŒº
    if paper_file is not None and physical_file is not None:
        # è¯»å–æ•°æ®
        try:
            # è¯»å–çº¸è´§æ•°æ®
            if paper_file.name.endswith(('.xlsx', '.xls')):
                df_paper_raw = pd.read_excel(paper_file)
            else:
                df_paper_raw = pd.read_csv(paper_file)
            
            # è¯»å–å®è´§æ•°æ®
            if physical_file.name.endswith(('.xlsx', '.xls')):
                df_physical_raw = pd.read_excel(physical_file)
            else:
                df_physical_raw = pd.read_csv(physical_file)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            with st.expander("ğŸ“‹ åŸå§‹æ•°æ®é¢„è§ˆ", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**çº¸è´§æ•°æ®** ({len(df_paper_raw)}è¡Œ, {len(df_paper_raw.columns)}åˆ—)")
                    st.dataframe(df_paper_raw.head(10), use_container_width=True)
                    st.caption(f"å…³é”®å­—æ®µ: {', '.join(df_paper_raw.columns.tolist()[:5])}...")
                
                with col2:
                    st.markdown(f"**å®è´§æ•°æ®** ({len(df_physical_raw)}è¡Œ, {len(df_physical_raw.columns)}åˆ—)")
                    st.dataframe(df_physical_raw.head(10), use_container_width=True)
                    st.caption(f"å…³é”®å­—æ®µ: {', '.join(df_physical_raw.columns.tolist()[:5])}...")
            
            # æ˜¾ç¤ºåŒ¹é…è§„åˆ™è¯´æ˜
            st.markdown(f'''
            <div class="info-box">
            <h4>ğŸ¯ åŒ¹é…è§„åˆ™è¯´æ˜</h4>
            <ul>
            <li><b>ä¼˜å…ˆçº§1:</b> ä¼˜å…ˆåŒ¹é…BRENTè®¡ä»·å“ç§ï¼ŒJCCæ¬¡ä¹‹</li>
            <li><b>ä¼˜å…ˆçº§2:</b> æŒ‰phy-2026-04 â†’ 05 â†’ 01 â†’ 02 â†’ 03é¡ºåºåŒ¹é…</li>
            <li><b>æ—¶é—´é™åˆ¶:</b> ä»…åŒ¹é…æŒ‡å®šæ—¥æœŸï¼ˆ{designation_date}ï¼‰ä¹‹åçš„çº¸è´§äº¤æ˜“</li>
            <li><b>æ•°é‡:</b> æ­£æ•°ä¸ºå¼€ä»“ï¼Œè´Ÿæ•°ä¸ºå¹³ä»“</li>
            <li><b>åŠ æƒå‡ä»·:</b> è‡ªåŠ¨è®¡ç®—å¼€ä»“/å¹³ä»“åŠ æƒå¹³å‡ä»·æ ¼</li>
            </ul>
            </div>
            ''', unsafe_allow_html=True)
            
            # æ‰§è¡ŒåŒ¹é…æŒ‰é’®
            if st.button("ğŸš€ æ‰§è¡Œå¥—ä¿åŒ¹é…", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå¥—ä¿åŒ¹é…ï¼Œè¯·ç¨å€™..."):
                    try:
                        # æ‰§è¡ŒåŒ¹é…
                        (df_relations, df_physical_updated, 
                         df_paper_net, df_paper_processed,
                         open_summary, close_summary) = st.session_state.engine.run_matching(
                            df_paper_raw, df_physical_raw, str(designation_date)
                        )
                        
                        if df_relations is not None and not df_relations.empty:
                            # åˆ›å»ºåˆ†ææ¨¡å—
                            st.session_state.analysis = HedgeAnalysis(
                                df_relations, df_physical_updated, df_paper_net,
                                open_summary, close_summary
                            )
                            st.session_state.matching_complete = True
                            
                            # æ˜¾ç¤ºåŒ¹é…æˆåŠŸä¿¡æ¯
                            st.markdown(f'''
                            <div class="success-box">
                            <h4>âœ… å¥—ä¿åŒ¹é…æˆåŠŸå®Œæˆï¼</h4>
                            <p>åŒ¹é…æ—¥æœŸèŒƒå›´: {designation_date} ä¹‹å</p>
                            <p>åŒ¹é…ä¼˜å…ˆçº§: BRENTä¼˜å…ˆï¼Œå®è´§æŒ‰æŒ‡å®šé¡ºåºåŒ¹é…</p>
                            <p>åŒ¹é…è®°å½•æ•°: {len(df_relations)}æ¡</p>
                            </div>
                            ''', unsafe_allow_html=True)
                            
                        else:
                            st.markdown('<div class="warning-box">âš ï¸ åŒ¹é…è¿‡ç¨‹å®Œæˆï¼Œä½†æœªç”ŸæˆåŒ¹é…è®°å½•</div>', unsafe_allow_html=True)
                            st.info("å¯èƒ½çš„åŸå› ï¼š")
                            st.write("1. æŒ‡å®šæ—¥æœŸä¹‹åæ²¡æœ‰å¯ç”¨çš„çº¸è´§äº¤æ˜“")
                            st.write("2. å®è´§æ•°æ®ä¸­æ²¡æœ‰éœ€è¦åŒ¹é…çš„å¤´å¯¸")
                            st.write("3. å•†å“æˆ–æœˆä»½ä¸åŒ¹é…")
                            
                            # åˆ›å»ºç©ºçš„åˆ†ææ¨¡å—
                            st.session_state.analysis = HedgeAnalysis(
                                pd.DataFrame(), df_physical_raw, pd.DataFrame(),
                                pd.DataFrame(), pd.DataFrame()
                            )
                            st.session_state.matching_complete = True
                            
                    except Exception as e:
                        st.markdown(f'<div class="error-box">âŒ åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}</div>', unsafe_allow_html=True)
                        
                        # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
                        with st.expander("æŸ¥çœ‹é”™è¯¯è¯¦æƒ…"):
                            st.exception(e)
        
        except Exception as e:
            st.error(f"æ•°æ®è¯»å–é”™è¯¯: {str(e)}")
            st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¹¶åŒ…å«å¿…è¦çš„å­—æ®µã€‚")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.matching_complete and st.session_state.analysis is not None:
        analysis = st.session_state.analysis
        
        if not analysis.df_relations.empty:
            st.markdown("---")
            st.markdown('<h2 class="sub-header">ğŸ“Š åŒ¹é…åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
            
            # 1. æ¦‚è§ˆæŒ‡æ ‡
            analysis.create_summary_metrics()
            
            # 2. åŒ¹é…æ˜ç»†è¡¨
            st.markdown('<h3 class="sub-header">ğŸ“‹ åŒ¹é…æ˜ç»†è¡¨</h3>', unsafe_allow_html=True)
            
            # æ·»åŠ ç­›é€‰å™¨
            col1, col2 = st.columns(2)
            with col1:
                position_filter = st.selectbox(
                    "å¤´å¯¸ç±»å‹ç­›é€‰",
                    ["å…¨éƒ¨", "å¼€ä»“", "å¹³ä»“"],
                    index=0
                )
            
            with col2:
                if 'Commodity' in analysis.df_relations.columns:
                    commodity_options = analysis.df_relations['Commodity'].unique()
                    commodity_filter = st.multiselect(
                        "å•†å“ç­›é€‰",
                        options=commodity_options,
                        default=commodity_options
                    )
                else:
                    commodity_filter = []
            
            # åº”ç”¨ç­›é€‰
            filtered_df = analysis.df_relations.copy()
            if position_filter != "å…¨éƒ¨":
                filtered_df = filtered_df[filtered_df['Position_Type'] == position_filter]
            
            if commodity_filter:
                filtered_df = filtered_df[filtered_df['Commodity'].isin(commodity_filter)]
            
            # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®
            st.dataframe(filtered_df.head(max_rows), use_container_width=True)
            st.caption(f"æ˜¾ç¤º {len(filtered_df.head(max_rows))} æ¡è®°å½•ï¼Œå…± {len(filtered_df)} æ¡åŒ¹é…è®°å½• (ç­›é€‰å)")
            
            # 3. å¤´å¯¸æ±‡æ€»è¡¨ï¼ˆå¼€ä»“/å¹³ä»“åŠ æƒå‡ä»·ï¼‰
            if show_positions:
                st.markdown('<h3 class="sub-header">âš–ï¸ å¤´å¯¸æ±‡æ€»ä¸åŠ æƒå¹³å‡ä»·æ ¼</h3>', unsafe_allow_html=True)
                
                if not analysis.open_summary.empty or not analysis.close_summary.empty:
                    tabs = st.tabs(["å¼€ä»“æ±‡æ€»", "å¹³ä»“æ±‡æ€»"])
                    
                    with tabs[0]:
                        if not analysis.open_summary.empty:
                            st.dataframe(analysis.open_summary, use_container_width=True)
                            st.caption(f"å¼€ä»“å¤´å¯¸æ±‡æ€» ({len(analysis.open_summary)}ä¸ªå•†å“-æœˆä»½ç»„åˆ)")
                            
                            # æ˜¾ç¤ºå¼€ä»“åŠ æƒå¹³å‡ä»·æ ¼
                            st.subheader("å¼€ä»“åŠ æƒå¹³å‡ä»·æ ¼æ±‡æ€»")
                            for _, row in analysis.open_summary.iterrows():
                                st.write(f"**{row['Commodity']} - {row['Month']}**: "
                                        f"{row['æ€»æ•°é‡']:,.0f}æ¡¶ @ ${row['åŠ æƒå¹³å‡ä»·æ ¼']:.2f}")
                        else:
                            st.info("æ— å¼€ä»“å¤´å¯¸æ•°æ®")
                    
                    with tabs[1]:
                        if not analysis.close_summary.empty:
                            st.dataframe(analysis.close_summary, use_container_width=True)
                            st.caption(f"å¹³ä»“å¤´å¯¸æ±‡æ€» ({len(analysis.close_summary)}ä¸ªå•†å“-æœˆä»½ç»„åˆ)")
                            
                            # æ˜¾ç¤ºå¹³ä»“åŠ æƒå¹³å‡ä»·æ ¼
                            st.subheader("å¹³ä»“åŠ æƒå¹³å‡ä»·æ ¼æ±‡æ€»")
                            for _, row in analysis.close_summary.iterrows():
                                st.write(f"**{row['Commodity']} - {row['Month']}**: "
                                        f"{row['æ€»æ•°é‡']:,.0f}æ¡¶ @ ${row['åŠ æƒå¹³å‡ä»·æ ¼']:.2f}")
                        else:
                            st.info("æ— å¹³ä»“å¤´å¯¸æ•°æ®")
                else:
                    st.info("æš‚æ— å¤´å¯¸æ±‡æ€»æ•°æ®")
            
            # 4. æ•°æ®å¯¼å‡º
            st.markdown("---")
            st.markdown('<h3 class="sub-header">ğŸ’¾ æ•°æ®å¯¼å‡º</h3>', unsafe_allow_html=True)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                # å¯¼å‡ºåŒ¹é…ç»“æœ
                csv_data = analysis.df_relations.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ åŒ¹é…ç»“æœ",
                    data=csv_data,
                    file_name=f"hedge_matching_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col2:
                # å¯¼å‡ºå¼€ä»“æ±‡æ€»
                if not analysis.open_summary.empty:
                    open_csv = analysis.open_summary.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="âš–ï¸ å¼€ä»“æ±‡æ€»",
                        data=open_csv,
                        file_name=f"open_positions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            
            with col3:
                # å¯¼å‡ºå¹³ä»“æ±‡æ€»
                if not analysis.close_summary.empty:
                    close_csv = analysis.close_summary.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="âš–ï¸ å¹³ä»“æ±‡æ€»",
                        data=close_csv,
                        file_name=f"close_positions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            
            with col4:
                # å¯¼å‡ºæ‰€æœ‰æ•°æ®
                @st.cache_data
                def convert_to_excel(df_dict):
                    output = io.BytesIO()
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        for sheet_name, df in df_dict.items():
                            if df is not None and not df.empty:
                                df.to_excel(writer, sheet_name=sheet_name, index=False)
                    return output.getvalue()
                
                excel_data = convert_to_excel({
                    "åŒ¹é…ç»“æœ": analysis.df_relations,
                    "å¼€ä»“æ±‡æ€»": analysis.open_summary,
                    "å¹³ä»“æ±‡æ€»": analysis.close_summary,
                    "å®è´§æ•°æ®": analysis.df_physical,
                    "çº¸è´§å‡€ä»“": analysis.df_paper_net
                })
                
                st.download_button(
                    label="ğŸ“Š å®Œæ•´æ•°æ®",
                    data=excel_data,
                    file_name=f"hedge_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
        else:
            st.markdown('<div class="info-box">ğŸ“Š åŒ¹é…å®Œæˆï¼Œä½†æœªæ‰¾åˆ°åŒ¹é…è®°å½•</div>', unsafe_allow_html=True)
            st.info("å»ºè®®æ£€æŸ¥ï¼š")
            st.write("1. ç¡®è®¤æŒ‡å®šæ—¥æœŸæ˜¯å¦æ­£ç¡®")
            st.write("2. æ£€æŸ¥çº¸è´§å’Œå®è´§çš„å•†å“åç§°æ˜¯å¦ä¸€è‡´")
            st.write("3. ç¡®è®¤å®è´§æ•°æ®ä¸­æœ‰éœ€è¦åŒ¹é…çš„å¤´å¯¸")
    
    else:
        # æ¬¢è¿é¡µé¢
        if not (paper_file and physical_file):
            st.markdown("---")
            st.markdown('<div class="info-box">ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ çº¸è´§å’Œå®è´§æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ</div>', unsafe_allow_html=True)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("""
                ### ğŸ¯ ç³»ç»Ÿå·¥ä½œæµç¨‹ (v2.0)
                
                1. **æ•°æ®ä¸Šä¼ **
                   - çº¸è´§äº¤æ˜“æ•°æ® (åŒ…å«äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡ã€å•†å“ã€ä»·æ ¼ç­‰)
                   - å®è´§æŒä»“æ•°æ® (åŒ…å«Cargo_IDã€äº¤æ˜“é‡ã€å¥—ä¿ä»£ç†ã€ç›®æ ‡æœˆä»½ç­‰)
                
                2. **æ™ºèƒ½åŒ¹é… (æŒ‰æ–°è§„åˆ™)**
                   - **æ—¶é—´è¿‡æ»¤**: ä»…åŒ¹é…æŒ‡å®šæ—¥æœŸ(2025å¹´11æœˆ12æ—¥)ä¹‹åçš„çº¸è´§äº¤æ˜“
                   - **ä¼˜å…ˆçº§1**: BRENTè®¡ä»·å“ç§ä¼˜å…ˆï¼ŒJCCæ¬¡ä¹‹
                   - **ä¼˜å…ˆçº§2**: å®è´§æŒ‰ phy-2026-04 â†’ 05 â†’ 01 â†’ 02 â†’ 03 é¡ºåºåŒ¹é…
                   - **å¤´å¯¸åŒºåˆ†**: æ­£æ•°ä¸ºå¼€ä»“ï¼Œè´Ÿæ•°ä¸ºå¹³ä»“
                
                3. **åŠ æƒå‡ä»·è®¡ç®—**
                   - **å¼€ä»“å‡ä»·**: æŒ‰å•†å“å’Œæœˆä»½è®¡ç®—åŠ æƒå¹³å‡å¼€ä»“ä»·æ ¼
                   - **å¹³ä»“å‡ä»·**: æŒ‰å•†å“å’Œæœˆä»½è®¡ç®—åŠ æƒå¹³å‡å¹³ä»“ä»·æ ¼
                   - **æœ‰æ•ˆæ€§æµ‹è¯•**: ä¸ºå¥—ä¿æœ‰æ•ˆæ€§æµ‹è¯•æä¾›åŸºç¡€æ•°æ®
                
                4. **æ•°æ®å¯¼å‡º**
                   - åŒ¹é…ç»“æœCSV
                   - å¼€ä»“/å¹³ä»“æ±‡æ€»CSV
                   - å®Œæ•´æ•°æ®Excel
                """)
            
            with col2:
                st.markdown("""
                ### ğŸ“‹ æ•°æ®è¦æ±‚
                
                **çº¸è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Trade Date`: äº¤æ˜“æ—¥æœŸ
                - `Volume`: äº¤æ˜“é‡ (æ­£ä¹°è´Ÿå–)
                - `Commodity`: å•†å“å“ç§
                - `Month`: åˆçº¦æœˆä»½ (å¯é€‰)
                - `Price`: äº¤æ˜“ä»·æ ¼ (æ¨è)
                
                **å®è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Cargo_ID`: å®è´§ç¼–å· (å»ºè®®åŒ…å«å¹´ä»½æœˆä»½)
                - `Volume`: äº¤æ˜“é‡
                - `Hedge_Proxy`: å¥—ä¿ä»£ç† (å¦‚BRENT, JCC)
                - `Target_Contract_Month`: ç›®æ ‡æœˆä»½
                
                **åŒ¹é…è§„åˆ™:**
                - ä»…åŒ¹é…æŒ‡å®šæ—¥æœŸä¹‹åçš„äº¤æ˜“
                - BRENTä¼˜å…ˆäºJCC
                - ç‰¹å®šCargo_IDä¼˜å…ˆé¡ºåº
                - è‡ªåŠ¨è®¡ç®—åŠ æƒå‡ä»·
                """)

if __name__ == "__main__":
    main()
