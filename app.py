import streamlit as st
import pandas as pd
import numpy as np
import io
import time
import warnings
from datetime import datetime, timedelta
from collections import deque
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import re
import json

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------------------------------------
# 1. æ ¸å¿ƒåŒ¹é…å¼•æ“ (æ ¹æ®æ–°éœ€æ±‚æ›´æ–°)
# ---------------------------------------------------------

class HedgeMatchingEngine:
    """å¥—ä¿åŒ¹é…å¼•æ“ - æ›´æ–°ç‰ˆ"""
    
    def __init__(self):
        self.df_paper = None
        self.df_physical = None
        self.df_paper_net = None
        self.df_relations = None
        self.df_physical_updated = None
        self.open_positions_summary = None  # å¼€ä»“æ±‡æ€»
        self.close_positions_summary = None  # å¹³ä»“æ±‡æ€»
        
    def clean_str(self, series):
        """æ¸…æ´—å­—ç¬¦ä¸²"""
        return series.astype(str).str.strip().str.upper().replace('NAN', '')
    
    def standardize_month(self, series):
        """æ ‡å‡†åŒ–æœˆä»½æ ¼å¼"""
        s = series.astype(str).str.strip().str.upper()
        s = s.str.replace('-', ' ', regex=False).str.replace('/', ' ', regex=False)
        dates = pd.to_datetime(s, errors='coerce')
        result = dates.dt.strftime('%b %y').str.upper()
        mask_invalid = dates.isna()
        
        if mask_invalid.any():
            invalid = s[mask_invalid]
            def swap_if_match(val):
                m = re.match(r'^(\d{2})\s*([A-Z]{3})$', val)
                if m:
                    yr, mon = m.groups()
                    return f"{mon} {yr}"
                return val
            swapped = invalid.map(swap_if_match)
            swapped_dates = pd.to_datetime(swapped, errors='coerce')
            swapped_formatted = swapped_dates.dt.strftime('%b %y').str.upper()
            result.loc[mask_invalid & swapped_dates.notna()] = swapped_formatted.loc[swapped_dates.notna()]
            result.loc[mask_invalid & swapped_dates.isna()] = swapped.loc[swapped_dates.isna()]
        return result
    
    def calculate_net_positions(self, df_paper, designation_date):
        """FIFOå‡€ä»“è®¡ç®— - è¿‡æ»¤æŒ‡å®šæ—¥æœŸå‰çš„äº¤æ˜“"""
        st.info("ğŸ”„ æ‰§è¡Œçº¸è´§å†…éƒ¨å¯¹å†² (FIFO Netting)...")
        progress_bar = st.progress(0)
        
        # è¿‡æ»¤æŒ‡å®šæ—¥æœŸä¹‹å‰çš„äº¤æ˜“ï¼ˆä¸å‚ä¸åŒ¹é…ï¼‰
        df_paper_filtered = df_paper.copy()
        df_paper_filtered['Trade Date'] = pd.to_datetime(df_paper_filtered['Trade Date'], errors='coerce')
        
        if designation_date:
            designation_dt = pd.to_datetime(designation_date)
            before_mask = df_paper_filtered['Trade Date'] < designation_dt
            if before_mask.any():
                st.warning(f"è¿‡æ»¤æ‰ {before_mask.sum()} æ¡æŒ‡å®šæ—¥æœŸ({designation_date})ä¹‹å‰çš„çº¸è´§äº¤æ˜“")
                df_paper_filtered = df_paper_filtered[~before_mask].copy()
        
        if df_paper_filtered.empty:
            st.error("æŒ‡å®šæ—¥æœŸä¹‹åæ²¡æœ‰å¯ç”¨çš„çº¸è´§äº¤æ˜“æ•°æ®")
            return pd.DataFrame()
        
        df_paper_filtered = df_paper_filtered.sort_values(by='Trade Date').reset_index(drop=True)
        df_paper_filtered['Group_Key'] = df_paper_filtered['Std_Commodity'] + "_" + df_paper_filtered['Month']
        records = df_paper_filtered.to_dict('records')
        groups = {}
        
        # åˆ†ç»„
        for i, row in enumerate(records):
            key = row['Group_Key']
            if key not in groups:
                groups[key] = []
            groups[key].append(i)
            if i % 100 == 0:
                progress_bar.progress(min(i / len(records) * 0.5, 0.5))
        
        # FIFOå‡€é¢åŒ–
        group_count = 0
        total_groups = len(groups)
        for key, indices in groups.items():
            open_queue = deque()
            for idx in indices:
                row = records[idx]
                current_vol = row.get('Volume', 0)
                records[idx]['Net_Open_Vol'] = current_vol
                records[idx]['Closed_Vol'] = 0
                records[idx]['Close_Events'] = []
                
                if abs(current_vol) < 0.0001:
                    continue
                
                current_sign = 1 if current_vol > 0 else -1
                
                # å°è¯•ä¸é˜Ÿåˆ—ä¸­çš„äº¤æ˜“æŠµæ¶ˆ
                while open_queue:
                    q_idx, q_vol, q_sign = open_queue[0]
                    if q_sign != current_sign:  # æ–¹å‘ç›¸åæ‰èƒ½æŠµæ¶ˆ
                        offset = min(abs(current_vol), abs(q_vol))
                        current_vol -= (current_sign * offset)
                        q_vol -= (q_sign * offset)
                        
                        # è®°å½•å¹³ä»“äº‹ä»¶
                        close_event = {
                            'Ref': str(records[idx].get('Recap No', '')),
                            'Date': records[idx].get('Trade Date'),
                            'Vol': offset,
                            'Price': records[idx].get('Price', 0),
                            'Commodity': records[idx].get('Std_Commodity'),
                            'Month': records[idx].get('Month')
                        }
                        records[q_idx]['Close_Events'].append(close_event)
                        records[q_idx]['Closed_Vol'] += offset
                        records[q_idx]['Net_Open_Vol'] = q_vol
                        records[idx]['Closed_Vol'] += offset
                        records[idx]['Net_Open_Vol'] = current_vol
                        
                        if abs(q_vol) < 0.0001:
                            open_queue.popleft()
                        else:
                            open_queue[0] = (q_idx, q_vol, q_sign)
                        
                        if abs(current_vol) < 0.0001:
                            break
                    else:
                        break
                
                # å‰©ä½™éƒ¨åˆ†å…¥é˜Ÿ
                if abs(current_vol) > 0.0001:
                    open_queue.append((idx, current_vol, current_sign))
            
            group_count += 1
            progress_bar.progress(0.5 + (group_count / total_groups) * 0.5)
        
        progress_bar.progress(1.0)
        st.success(f"âœ… çº¸è´§å†…éƒ¨å¯¹å†²å®Œæˆï¼å…±å¤„ç† {len(groups)} ä¸ªå•†å“-æœˆä»½ç»„åˆ")
        return pd.DataFrame(records)
    
    def get_physical_priority(self, cargo_id):
        """è·å–å®è´§åŒ¹é…ä¼˜å…ˆçº§"""
        # æŒ‰ç…§ä½ çš„è¦æ±‚ï¼šphy-2026-04 -> phy-2026-05 -> phy-2026-01 -> phy-2026-02 -> phy-2026-03
        priority_map = {
            'PHY-2026-04': 1,
            'PHY-2026-05': 2,
            'PHY-2026-01': 3,
            'PHY-2026-02': 4,
            'PHY-2026-03': 5
        }
        
        # åŒ¹é… cargo_id ä¸­çš„å…³é”®éƒ¨åˆ†
        for key in priority_map:
            if key in cargo_id.upper():
                return priority_map[key]
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œè¿”å›é»˜è®¤å€¼
        return 100
    
    def get_commodity_priority(self, commodity):
        """è·å–å•†å“ä¼˜å…ˆçº§ï¼šBRENTä¼˜å…ˆï¼ŒJCCæ¬¡ä¹‹"""
        commodity_upper = str(commodity).upper()
        if 'BRENT' in commodity_upper:
            return 1
        elif 'JCC' in commodity_upper:
            return 2
        else:
            return 3
    
    def match_hedges(self, df_physical, df_paper_net, designation_date):
        """å®è´§åŒ¹é… - æ ¹æ®æ–°éœ€æ±‚æ›´æ–°"""
        st.info("ğŸ”„ å¼€å§‹å®è´§åŒ¹é…...")
        progress_bar = st.progress(0)
        
        hedge_relations = []
        open_positions = []  # è®°å½•å¼€ä»“å¤´å¯¸
        close_positions = []  # è®°å½•å¹³ä»“å¤´å¯¸
        
        active_paper = df_paper_net.copy()
        active_paper['Allocated_To_Phy'] = 0.0
        active_paper['_original_index'] = active_paper.index
        
        df_phy = df_physical.copy()
        df_phy['_orig_idx'] = df_phy.index
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºå®è´§
        # 1. å•†å“ä¼˜å…ˆçº§ï¼šBRENTä¼˜å…ˆ
        # 2. Cargo_IDä¼˜å…ˆçº§ï¼šphy-2026-04 -> 05 -> 01 -> 02 -> 03
        # 3. æŒ‰åŸç´¢å¼•ä½œä¸ºæœ€åæ’åºä¾æ®
        
        if 'Hedge_Proxy' in df_phy.columns:
            df_phy['_commodity_priority'] = df_phy['Hedge_Proxy'].apply(self.get_commodity_priority)
        else:
            df_phy['_commodity_priority'] = 3
        
        if 'Cargo_ID' in df_phy.columns:
            df_phy['_cargo_priority'] = df_phy['Cargo_ID'].apply(self.get_physical_priority)
        else:
            df_phy['_cargo_priority'] = 100
        
        # æŒ‰ä¼˜å…ˆçº§æ’åº
        df_phy = df_phy.sort_values(
            by=['_commodity_priority', '_cargo_priority', '_orig_idx']
        ).reset_index(drop=True)
        
        # ç§»é™¤ä¸´æ—¶åˆ—
        df_phy = df_phy.drop(columns=['_commodity_priority', '_cargo_priority'])
        
        total_cargos = len(df_phy)
        
        for idx, (_, cargo) in enumerate(df_phy.iterrows()):
            cargo_id = cargo.get('Cargo_ID')
            phy_vol = cargo.get('Unhedged_Volume', 0)
            
            if abs(phy_vol) < 0.0001:
                continue
            
            proxy = str(cargo.get('Hedge_Proxy', ''))
            target_month = cargo.get('Target_Contract_Month', None)
            phy_dir = cargo.get('Direction', 'Buy')
            desig_date = cargo.get('Designation_Date', pd.NaT)
            
            # ç­›é€‰å€™é€‰äº¤æ˜“ - ä¼˜å…ˆåŒ¹é…ç›¸åŒå“ç§å’Œæœˆä»½
            candidates_df = active_paper[
                (active_paper['Std_Commodity'].str.contains(proxy, regex=False)) &
                (active_paper['Month'] == target_month)
            ].copy()
            
            # å¦‚æœåŒæœˆä»½ä¸å¤Ÿï¼Œå°è¯•åŒ¹é…å…¶ä»–æœˆä»½çš„ç›¸åŒå“ç§
            if candidates_df.empty or candidates_df['Net_Open_Vol'].abs().sum() < abs(phy_vol):
                # æŸ¥æ‰¾ç›¸åŒå“ç§çš„æ‰€æœ‰äº¤æ˜“
                all_same_commodity = active_paper[
                    active_paper['Std_Commodity'].str.contains(proxy, regex=False)
                ].copy()
                
                if len(all_same_commodity) > 0:
                    # æŒ‰æ—¶é—´æ’åºï¼ˆFIFOï¼‰
                    all_same_commodity = all_same_commodity.sort_values('Trade Date')
                    candidates_df = pd.concat([candidates_df, all_same_commodity]).drop_duplicates()
            
            if candidates_df.empty:
                continue
            
            # æ—¶é—´æ’åºï¼šæœ‰æŒ‡å®šæ—¥æœŸæŒ‰æ—¶é—´å·®ï¼Œå¦åˆ™FIFO
            if pd.notna(desig_date) and not candidates_df['Trade Date'].isnull().all():
                candidates_df['Time_Lag_Days'] = (candidates_df['Trade Date'] - desig_date).dt.days
                candidates_df['Abs_Lag'] = candidates_df['Time_Lag_Days'].abs()
                candidates_df = candidates_df.sort_values(by=['Abs_Lag', 'Trade Date'])
            else:
                candidates_df['Time_Lag_Days'] = np.nan
                candidates_df = candidates_df.sort_values(by='Trade Date')
            
            # åˆ†é…åŒ¹é…
            for _, ticket in candidates_df.iterrows():
                if abs(phy_vol) < 1:
                    break
                
                original_index = ticket['_original_index']
                curr_allocated = active_paper.at[original_index, 'Allocated_To_Phy']
                curr_total_vol = ticket.get('Volume', 0)
                curr_net_open = ticket.get('Net_Open_Vol', 0)
                avail = curr_net_open - curr_allocated
                
                if abs(avail) < 0.0001:
                    continue
                
                # ç¡®å®šåˆ†é…é‡ï¼ˆç¡®ä¿ç¬¦å·æ­£ç¡®ï¼‰
                alloc_amt_abs = abs(phy_vol) if abs(avail) >= abs(phy_vol) else abs(avail)
                # åˆ†é…é‡çš„ç¬¦å·ä¸å¯ç”¨é‡çš„ç¬¦å·ä¸€è‡´
                alloc_amt = np.sign(avail) * alloc_amt_abs
                phy_vol -= alloc_amt_abs if phy_vol > 0 else -alloc_amt_abs
                active_paper.at[original_index, 'Allocated_To_Phy'] += alloc_amt
                
                # è®°å½•å¼€ä»“å’Œå¹³ä»“
                ticket_commodity = ticket.get('Std_Commodity')
                ticket_month = ticket.get('Month')
                open_price = ticket.get('Price', 0)
                
                if alloc_amt > 0:  # å¼€ä»“
                    open_positions.append({
                        'Cargo_ID': cargo_id,
                        'Commodity': ticket_commodity,
                        'Month': ticket_month,
                        'Open_Date': ticket.get('Trade Date'),
                        'Volume': alloc_amt,
                        'Price': open_price,
                        'Ticket_ID': ticket.get('Recap No')
                    })
                elif alloc_amt < 0:  # å¹³ä»“
                    close_positions.append({
                        'Cargo_ID': cargo_id,
                        'Commodity': ticket_commodity,
                        'Month': ticket_month,
                        'Close_Date': ticket.get('Trade Date'),
                        'Volume': alloc_amt,  # è´Ÿæ•°
                        'Price': open_price,
                        'Ticket_ID': ticket.get('Recap No')
                    })
                
                # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
                mtm_price = ticket.get('Mtm Price', open_price)
                total_pl_raw = ticket.get('Total P/L', 0)
                close_events = ticket.get('Close_Events', [])
                
                # æ ¼å¼åŒ–å¹³ä»“è·¯å¾„
                close_path_str = ""
                if close_events:
                    sorted_events = sorted(close_events, key=lambda x: x['Date'] if pd.notna(x['Date']) else pd.Timestamp.min)
                    details = []
                    for e in sorted_events:
                        d_str = e['Date'].strftime('%Y-%m-%d') if pd.notna(e['Date']) else 'N/A'
                        p_str = f"@{e['Price']}" if pd.notna(e['Price']) else ""
                        details.append(f"[{d_str} Tkt#{e['Ref']} Vol:{e['Vol']:.0f} {p_str}]")
                    close_path_str = " -> ".join(details)
                
                # è®¡ç®—åˆ†é…æ¯”ä¾‹
                ratio = abs(alloc_amt) / abs(curr_total_vol) if abs(curr_total_vol) > 0 else 0
                unrealized_mtm = (mtm_price - open_price) * alloc_amt
                allocated_total_pl = total_pl_raw * ratio
                
                hedge_relations.append({
                    'Cargo_ID': cargo_id,
                    'Proxy': proxy,
                    'Designation_Date': desig_date,
                    'Open_Date': ticket.get('Trade Date'),
                    'Time_Lag': ticket.get('Time_Lag_Days'),
                    'Ticket_ID': ticket.get('Recap No'),
                    'Month': ticket.get('Month'),
                    'Commodity': ticket_commodity,
                    'Allocated_Vol': alloc_amt,  # æ­£æ•°ä¸ºå¼€ä»“ï¼Œè´Ÿæ•°ä¸ºå¹³ä»“
                    'Trade_Volume': ticket.get('Volume', 0),
                    'Trade_Net_Open': ticket.get('Net_Open_Vol', 0),
                    'Trade_Closed_Vol': ticket.get('Closed_Vol', 0),
                    'Open_Price': open_price,
                    'MTM_Price': mtm_price,
                    'Alloc_Unrealized_MTM': round(unrealized_mtm, 2),
                    'Alloc_Total_PL': round(allocated_total_pl, 2),
                    'Close_Path_Details': close_path_str,
                    'Position_Type': 'å¼€ä»“' if alloc_amt > 0 else 'å¹³ä»“'
                })
                
                # æ›´æ–°å®è´§æœªå¯¹å†²é‡
                orig_idx = cargo.get('_orig_idx')
                if orig_idx in df_physical.index:
                    df_physical.at[orig_idx, 'Unhedged_Volume'] = phy_vol
            
            progress_bar.progress((idx + 1) / total_cargos)
        
        # æ›´æ–°åˆ†é…é‡
        cols_to_update = active_paper[['_original_index', 'Allocated_To_Phy']].set_index('_original_index')
        df_paper_net.update(cols_to_update)
        
        # è®¡ç®—å¼€ä»“å’Œå¹³ä»“æ±‡æ€»
        self.open_positions_summary = self.calculate_weighted_average(open_positions, 'å¼€ä»“')
        self.close_positions_summary = self.calculate_weighted_average(close_positions, 'å¹³ä»“')
        
        progress_bar.progress(1.0)
        df_relations = pd.DataFrame(hedge_relations)
        st.success(f"âœ… å®è´§åŒ¹é…å®Œæˆï¼å…±ç”Ÿæˆ {len(df_relations)} æ¡åŒ¹é…è®°å½•")
        
        return df_relations, df_physical
    
    def calculate_weighted_average(self, positions, position_type):
        """è®¡ç®—åŠ æƒå¹³å‡ä»·æ ¼"""
        if not positions:
            return pd.DataFrame()
        
        df = pd.DataFrame(positions)
        
        # ç§»é™¤ç¬¦å·
        if position_type == 'å¹³ä»“':
            df['Volume_Abs'] = abs(df['Volume'])
        else:
            df['Volume_Abs'] = df['Volume']
        
        # æŒ‰å•†å“å’Œæœˆä»½åˆ†ç»„è®¡ç®—åŠ æƒå¹³å‡
        summary = df.groupby(['Commodity', 'Month']).apply(
            lambda x: pd.Series({
                'æ€»æ•°é‡': x['Volume_Abs'].sum(),
                'åŠ æƒå¹³å‡ä»·æ ¼': np.average(x['Price'], weights=x['Volume_Abs']),
                'äº¤æ˜“æ¬¡æ•°': len(x),
                'æœ€æ—©äº¤æ˜“æ—¥æœŸ': x.iloc[0]['Open_Date'] if position_type == 'å¼€ä»“' else x.iloc[0]['Close_Date'],
                'æœ€æ™šäº¤æ˜“æ—¥æœŸ': x.iloc[-1]['Open_Date'] if position_type == 'å¼€ä»“' else x.iloc[-1]['Close_Date']
            })
        ).reset_index()
        
        summary['å¤´å¯¸ç±»å‹'] = position_type
        return summary
    
    def run_matching(self, df_paper_raw, df_physical_raw, designation_date="2024-11-12"):
        """æ‰§è¡Œå®Œæ•´åŒ¹é…æµç¨‹"""
        # æ•°æ®é¢„å¤„ç†
        st.info("ğŸ”„ æ•°æ®é¢„å¤„ç†ä¸­...")
        
        # çº¸è´§é¢„å¤„ç†
        df_paper = df_paper_raw.copy()
        
        # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
        required_cols_paper = ['Trade Date', 'Volume', 'Commodity']
        for col in required_cols_paper:
            if col not in df_paper.columns:
                st.error(f"çº¸è´§æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return None, None, None, None, None, None
        
        # æ ‡å‡†åŒ–å¤„ç†
        df_paper['Trade Date'] = pd.to_datetime(df_paper['Trade Date'], errors='coerce')
        df_paper['Volume'] = pd.to_numeric(df_paper['Volume'], errors='coerce').fillna(0)
        df_paper['Std_Commodity'] = self.clean_str(df_paper['Commodity'])
        
        if 'Month' in df_paper.columns:
            df_paper['Month'] = self.standardize_month(df_paper['Month'])
        else:
            # å¦‚æœæ²¡æœ‰Monthåˆ—ï¼Œå°è¯•ä»å…¶ä»–åˆ—æ¨æ–­æˆ–åˆ›å»ºé»˜è®¤å€¼
            df_paper['Month'] = df_paper['Trade Date'].dt.strftime('%b %y').str.upper()
        
        # å¤„ç†ç¼ºå¤±å­—æ®µ
        if 'Recap No' not in df_paper.columns:
            df_paper['Recap No'] = [f"TKT-{i+1:04d}" for i in range(len(df_paper))]
        
        for col in ['Price', 'Mtm Price', 'Total P/L']:
            if col not in df_paper.columns:
                df_paper[col] = 0.0
        
        # å®è´§é¢„å¤„ç†
        df_physical = df_physical_raw.copy()
        
        # æ ‡å‡†åŒ–åˆ—å
        col_mapping = {
            'Target_Pricing_Month': 'Target_Contract_Month',
            'Month': 'Target_Contract_Month',
            'Hedge_Proxy': 'Hedge_Proxy',
            'Direction': 'Direction'
        }
        
        for old_col, new_col in col_mapping.items():
            if old_col in df_physical.columns and new_col not in df_physical.columns:
                df_physical[new_col] = df_physical[old_col]
        
        # ç¡®ä¿å¿…è¦åˆ—
        if 'Volume' in df_physical.columns:
            df_physical['Volume'] = pd.to_numeric(df_physical['Volume'], errors='coerce').fillna(0)
            df_physical['Unhedged_Volume'] = df_physical['Volume']
        
        if 'Hedge_Proxy' in df_physical.columns:
            df_physical['Hedge_Proxy'] = self.clean_str(df_physical['Hedge_Proxy'])
        
        if 'Target_Contract_Month' in df_physical.columns:
            df_physical['Target_Contract_Month'] = self.standardize_month(df_physical['Target_Contract_Month'])
        
        # æŒ‡å®šæ—¥æœŸ
        date_cols = ['Designation_Date', 'Pricing_Start', 'Trade Date']
        for col in date_cols:
            if col in df_physical.columns:
                df_physical['Designation_Date'] = pd.to_datetime(df_physical[col], errors='coerce')
                break
        else:
            df_physical['Designation_Date'] = pd.NaT
        
        # æ‰§è¡ŒåŒ¹é…
        self.df_paper_net = self.calculate_net_positions(df_paper, designation_date)
        
        if self.df_paper_net.empty:
            return None, None, None, None, None, None
        
        self.df_relations, self.df_physical_updated = self.match_hedges(
            df_physical, self.df_paper_net, designation_date
        )
        
        return (self.df_relations, self.df_physical_updated, 
                self.df_paper_net, df_paper, 
                self.open_positions_summary, self.close_positions_summary)

# ---------------------------------------------------------
# 2. åˆ†ææ¨¡å— (åŸºäºçœŸå®åŒ¹é…ç»“æœ)
# ---------------------------------------------------------

class HedgeAnalysis:
    """å¥—ä¿åˆ†ææ¨¡å—"""
    
    def __init__(self, df_relations, df_physical, df_paper_net, 
                 open_summary=None, close_summary=None):
        self.df_relations = df_relations
        self.df_physical = df_physical
        self.df_paper_net = df_paper_net
        self.open_summary = open_summary
        self.close_summary = close_summary
        self.summary_stats = {}
        self.calculate_summary()
    
    def calculate_summary(self):
        """è®¡ç®—æ±‡æ€»ç»Ÿè®¡"""
        if self.df_relations.empty:
            return
        
        # åŒ¹é…ç»Ÿè®¡
        total_matched = abs(self.df_relations['Allocated_Vol']).sum()
        total_physical = abs(self.df_physical['Volume']).sum() if 'Volume' in self.df_physical.columns else 0
        match_rate = (total_matched / total_physical * 100) if total_physical > 0 else 0
        
        # å¼€ä»“å¹³ä»“ç»Ÿè®¡
        open_positions = self.df_relations[self.df_relations['Allocated_Vol'] > 0]
        close_positions = self.df_relations[self.df_relations['Allocated_Vol'] < 0]
        
        open_volume = open_positions['Allocated_Vol'].sum() if not open_positions.empty else 0
        close_volume = abs(close_positions['Allocated_Vol'].sum()) if not close_positions.empty else 0
        
        # è´¢åŠ¡ç»Ÿè®¡
        total_pl = self.df_relations['Alloc_Total_PL'].sum()
        total_unrealized = self.df_relations['Alloc_Unrealized_MTM'].sum()
        
        # æ•°é‡ç»Ÿè®¡
        matched_cargos = self.df_relations['Cargo_ID'].nunique()
        total_cargos = self.df_physical['Cargo_ID'].nunique() if 'Cargo_ID' in self.df_physical.columns else 0
        total_tickets = len(self.df_relations)
        
        # æ—¶é—´ç»Ÿè®¡
        if 'Time_Lag' in self.df_relations.columns:
            avg_time_lag = self.df_relations['Time_Lag'].abs().mean()
            std_time_lag = self.df_relations['Time_Lag'].abs().std()
        else:
            avg_time_lag = std_time_lag = 0
        
        self.summary_stats = {
            'total_matched': total_matched,
            'total_physical': total_physical,
            'match_rate': match_rate,
            'open_volume': open_volume,
            'close_volume': close_volume,
            'total_pl': total_pl,
            'total_unrealized': total_unrealized,
            'matched_cargos': matched_cargos,
            'total_cargos': total_cargos,
            'total_tickets': total_tickets,
            'open_count': len(open_positions),
            'close_count': len(close_positions),
            'avg_time_lag': avg_time_lag,
            'std_time_lag': std_time_lag
        }
    
    def create_summary_metrics(self):
        """åˆ›å»ºæ¦‚è§ˆæŒ‡æ ‡å¡ç‰‡"""
        stats = self.summary_stats
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“Š åŒ¹é…ç‡", f"{stats['match_rate']:.1f}%", 
                     delta=f"{stats['total_matched']:,.0f}/{stats['total_physical']:,.0f}")
        
        with col2:
            coverage = (stats['matched_cargos'] / stats['total_cargos'] * 100) if stats['total_cargos'] > 0 else 0
            st.metric("ğŸ“¦ åŒ¹é…è¦†ç›–ç‡", f"{coverage:.1f}%",
                     delta=f"{stats['matched_cargos']}/{stats['total_cargos']}")
        
        with col3:
            st.metric("ğŸ’° æ€»P/L", f"${stats['total_pl']:,.2f}",
                     delta=f"æœªå®ç°: ${stats['total_unrealized']:,.2f}")
        
        with col4:
            st.metric("âš–ï¸ å¼€ä»“/å¹³ä»“", f"{stats['open_volume']:,.0f}/{stats['close_volume']:,.0f}",
                     delta=f"{stats['open_count']}/{stats['close_count']}ç¬”")
    
    def create_match_volume_chart(self):
        """åŒ¹é…é‡åˆ†å¸ƒå›¾è¡¨"""
        if self.df_relations.empty:
            return None
        
        # æŒ‰Cargo_IDå’Œå¤´å¯¸ç±»å‹æ±‡æ€»
        cargo_summary = self.df_relations.copy()
        cargo_summary['Allocated_Vol_Abs'] = abs(cargo_summary['Allocated_Vol'])
        cargo_summary = cargo_summary.groupby(['Cargo_ID', 'Position_Type'])['Allocated_Vol_Abs'].sum().reset_index()
        
        fig = px.bar(cargo_summary.sort_values('Allocated_Vol_Abs', ascending=False).head(40), 
                     x='Cargo_ID', y='Allocated_Vol_Abs',
                     color='Position_Type',
                     title='ğŸ“ˆ å„Cargo_IDåŒ¹é…é‡åˆ†å¸ƒ',
                     labels={'Allocated_Vol_Abs': 'åŒ¹é…é‡', 'Cargo_ID': 'å®è´§ç¼–å·'},
                     barmode='group')
        fig.update_layout(xaxis_tickangle=-45)
        return fig
    
    def create_position_summary_table(self):
        """åˆ›å»ºå¤´å¯¸æ±‡æ€»è¡¨"""
        tabs = st.tabs(["å¼€ä»“æ±‡æ€»", "å¹³ä»“æ±‡æ€»"])
        
        with tabs[0]:
            if self.open_summary is not None and not self.open_summary.empty:
                st.dataframe(self.open_summary, use_container_width=True)
                st.caption(f"å¼€ä»“å¤´å¯¸æ±‡æ€» ({len(self.open_summary)}ä¸ªå•†å“-æœˆä»½ç»„åˆ)")
                
                # æ˜¾ç¤ºå¼€ä»“åŠ æƒå¹³å‡ä»·æ ¼
                st.subheader("å¼€ä»“åŠ æƒå¹³å‡ä»·æ ¼æ±‡æ€»")
                for _, row in self.open_summary.iterrows():
                    st.write(f"**{row['Commodity']} - {row['Month']}**: "
                            f"{row['æ€»æ•°é‡']:,.0f}æ¡¶ @ ${row['åŠ æƒå¹³å‡ä»·æ ¼']:.2f}")
            else:
                st.info("æ— å¼€ä»“å¤´å¯¸æ•°æ®")
        
        with tabs[1]:
            if self.close_summary is not None and not self.close_summary.empty:
                st.dataframe(self.close_summary, use_container_width=True)
                st.caption(f"å¹³ä»“å¤´å¯¸æ±‡æ€» ({len(self.close_summary)}ä¸ªå•†å“-æœˆä»½ç»„åˆ)")
                
                # æ˜¾ç¤ºå¹³ä»“åŠ æƒå¹³å‡ä»·æ ¼
                st.subheader("å¹³ä»“åŠ æƒå¹³å‡ä»·æ ¼æ±‡æ€»")
                for _, row in self.close_summary.iterrows():
                    st.write(f"**{row['Commodity']} - {row['Month']}**: "
                            f"{row['æ€»æ•°é‡']:,.0f}æ¡¶ @ ${row['åŠ æƒå¹³å‡ä»·æ ¼']:.2f}")
            else:
                st.info("æ— å¹³ä»“å¤´å¯¸æ•°æ®")

# ---------------------------------------------------------
# 3. Streamlit ä¸»åº”ç”¨
# ---------------------------------------------------------

def main():
    st.set_page_config(
        page_title="å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ v2.0",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #374151;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        border-bottom: 2px solid #E5E7EB;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #D1FAE5;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #10B981;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #DBEAFE;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #3B82F6;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #FEF3C7;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #F59E0B;
        margin: 1rem 0;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # æ ‡é¢˜
    st.markdown('<h1 class="main-header">ğŸ“ˆ å®çº¸è´§å¥—ä¿åŒ¹é…åˆ†æç³»ç»Ÿ v2.0</h1>', unsafe_allow_html=True)
    st.markdown("### ä¸“ä¸šå¥—ä¿åŒ¹é…ä¸æœ‰æ•ˆæ€§æµ‹è¯•å·¥å…· | æ”¯æŒåŠ æƒå‡ä»·è®¡ç®—")
    
    # åˆå§‹åŒ–session state
    if 'engine' not in st.session_state:
        st.session_state.engine = HedgeMatchingEngine()
    if 'analysis' not in st.session_state:
        st.session_state.analysis = None
    if 'matching_complete' not in st.session_state:
        st.session_state.matching_complete = False
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.markdown("### ğŸ“ æ•°æ®ä¸Šä¼ ")
        
        paper_file = st.file_uploader(
            "çº¸è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="paper_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Trade Date, Volume, Commodityç­‰å­—æ®µ"
        )
        
        physical_file = st.file_uploader(
            "å®è´§æ•°æ®æ–‡ä»¶",
            type=["csv", "xlsx", "xls"],
            key="physical_uploader",
            help="æ”¯æŒCSV/Excelæ ¼å¼ï¼Œéœ€åŒ…å«Cargo_ID, Volume, Hedge_Proxyç­‰å­—æ®µ"
        )
        
        st.markdown("---")
        st.markdown("### âš™ï¸ åŒ¹é…è®¾ç½®")
        
        # æŒ‡å®šæ—¥æœŸè®¾ç½®
        designation_date = st.date_input(
            "æŒ‡å®šåŒ¹é…å¼€å§‹æ—¥æœŸ",
            value=datetime(2024, 11, 12),
            help="ä»è¯¥æ—¥æœŸå¼€å§‹çš„çº¸è´§äº¤æ˜“æ‰ä¼šå‚ä¸åŒ¹é…"
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“Š åˆ†æè®¾ç½®")
        
        show_charts = st.checkbox("æ˜¾ç¤ºåˆ†æå›¾è¡¨", value=True)
        show_positions = st.checkbox("æ˜¾ç¤ºå¤´å¯¸æ±‡æ€»", value=True)
        show_risk = st.checkbox("æ˜¾ç¤ºé£é™©æŒ‡æ ‡", value=False)
        max_rows = st.slider("è¡¨æ ¼æ˜¾ç¤ºè¡Œæ•°", 10, 200, 50)
        
        st.markdown("---")
        
        if st.button("ğŸ”„ é‡ç½®æ‰€æœ‰æ•°æ®", type="secondary"):
            st.session_state.engine = HedgeMatchingEngine()
            st.session_state.analysis = None
            st.session_state.matching_complete = False
            st.rerun()
    
    # ä¸»å†…å®¹åŒº
    if paper_file is not None and physical_file is not None:
        # è¯»å–æ•°æ®
        try:
            # è¯»å–çº¸è´§æ•°æ®
            if paper_file.name.endswith(('.xlsx', '.xls')):
                df_paper_raw = pd.read_excel(paper_file)
            else:
                df_paper_raw = pd.read_csv(paper_file)
            
            # è¯»å–å®è´§æ•°æ®
            if physical_file.name.endswith(('.xlsx', '.xls')):
                df_physical_raw = pd.read_excel(physical_file)
            else:
                df_physical_raw = pd.read_csv(physical_file)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            with st.expander("ğŸ“‹ åŸå§‹æ•°æ®é¢„è§ˆ", expanded=False):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown(f"**çº¸è´§æ•°æ®** ({len(df_paper_raw)}è¡Œ, {len(df_paper_raw.columns)}åˆ—)")
                    st.dataframe(df_paper_raw.head(10), use_container_width=True)
                    st.caption(f"å…³é”®å­—æ®µ: {', '.join(df_paper_raw.columns.tolist()[:5])}...")
                
                with col2:
                    st.markdown(f"**å®è´§æ•°æ®** ({len(df_physical_raw)}è¡Œ, {len(df_physical_raw.columns)}åˆ—)")
                    st.dataframe(df_physical_raw.head(10), use_container_width=True)
                    st.caption(f"å…³é”®å­—æ®µ: {', '.join(df_physical_raw.columns.tolist()[:5])}...")
            
            # æ˜¾ç¤ºåŒ¹é…è§„åˆ™è¯´æ˜
            st.markdown('<div class="info-box">'
                       '<h4>ğŸ¯ åŒ¹é…è§„åˆ™è¯´æ˜</h4>'
                       '<ul>'
                       '<li><b>ä¼˜å…ˆçº§1:</b> ä¼˜å…ˆåŒ¹é…BRENTè®¡ä»·å“ç§ï¼ŒJCCæ¬¡ä¹‹</li>'
                       '<li><b>ä¼˜å…ˆçº§2:</b> æŒ‰phy-2026-04 â†’ 05 â†’ 01 â†’ 02 â†’ 03é¡ºåºåŒ¹é…</li>'
                       '<li><b>æ—¶é—´é™åˆ¶:</b> ä»…åŒ¹é…æŒ‡å®šæ—¥æœŸï¼ˆ{designation_date}ï¼‰ä¹‹åçš„çº¸è´§äº¤æ˜“</li>'
                       '<li><b>æ•°é‡:</b> æ­£æ•°ä¸ºå¼€ä»“ï¼Œè´Ÿæ•°ä¸ºå¹³ä»“</li>'
                       '<li><b>åŠ æƒå‡ä»·:</b> è‡ªåŠ¨è®¡ç®—å¼€ä»“/å¹³ä»“åŠ æƒå¹³å‡ä»·æ ¼</li>'
                       '</ul>'
                       '</div>'.format(designation_date=designation_date), 
                       unsafe_allow_html=True)
            
            # æ‰§è¡ŒåŒ¹é…æŒ‰é’®
            if st.button("ğŸš€ æ‰§è¡Œå¥—ä¿åŒ¹é…", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå¥—ä¿åŒ¹é…ï¼Œè¯·ç¨å€™..."):
                    try:
                        # æ‰§è¡ŒåŒ¹é…
                        (df_relations, df_physical_updated, 
                         df_paper_net, df_paper_processed,
                         open_summary, close_summary) = st.session_state.engine.run_matching(
                            df_paper_raw, df_physical_raw, str(designation_date)
                        )
                        
                        if df_relations is not None:
                            # åˆ›å»ºåˆ†ææ¨¡å—
                            st.session_state.analysis = HedgeAnalysis(
                                df_relations, df_physical_updated, df_paper_net,
                                open_summary, close_summary
                            )
                            st.session_state.matching_complete = True
                            
                            # æ˜¾ç¤ºåŒ¹é…æˆåŠŸä¿¡æ¯
                            st.markdown('<div class="success-box">'
                                       '<h4>âœ… å¥—ä¿åŒ¹é…æˆåŠŸå®Œæˆï¼</h4>'
                                       f'<p>åŒ¹é…æ—¥æœŸèŒƒå›´: {designation_date} ä¹‹å</p>'
                                       f'<p>åŒ¹é…ä¼˜å…ˆçº§: BRENTä¼˜å…ˆï¼Œå®è´§æŒ‰æŒ‡å®šé¡ºåºåŒ¹é…</p>'
                                       '</div>', unsafe_allow_html=True)
                            
                            # æ˜¾ç¤ºåŒ¹é…è¿‡ç¨‹æ•°æ®
                            with st.expander("ğŸ“Š åŒ¹é…è¿‡ç¨‹æ•°æ®", expanded=False):
                                tab1, tab2, tab3, tab4 = st.tabs(["çº¸è´§å‡€ä»“", "å®è´§æ›´æ–°", "åŒ¹é…å…³ç³»", "å¤´å¯¸æ˜ç»†"])
                                
                                with tab1:
                                    st.dataframe(df_paper_net.head(20), use_container_width=True)
                                    st.caption(f"çº¸è´§å‡€ä»“æ•°æ® ({len(df_paper_net)}è¡Œ)")
                                
                                with tab2:
                                    st.dataframe(df_physical_updated.head(20), use_container_width=True)
                                    st.caption(f"æ›´æ–°åå®è´§æ•°æ® ({len(df_physical_updated)}è¡Œ)")
                                
                                with tab3:
                                    st.dataframe(df_relations.head(20), use_container_width=True)
                                    st.caption(f"åŒ¹é…å…³ç³»æ•°æ® ({len(df_relations)}è¡Œ)")
                                
                                with tab4:
                                    # å¼€ä»“å’Œå¹³ä»“æ˜ç»†
                                    open_df = df_relations[df_relations['Allocated_Vol'] > 0]
                                    close_df = df_relations[df_relations['Allocated_Vol'] < 0]
                                    
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        st.markdown("**å¼€ä»“æ˜ç»†**")
                                        st.dataframe(open_df.head(10), use_container_width=True)
                                        st.caption(f"å¼€ä»“è®°å½•: {len(open_df)}æ¡")
                                    
                                    with col2:
                                        st.markdown("**å¹³ä»“æ˜ç»†**")
                                        st.dataframe(close_df.head(10), use_container_width=True)
                                        st.caption(f"å¹³ä»“è®°å½•: {len(close_df)}æ¡")
                        else:
                            st.error("åŒ¹é…è¿‡ç¨‹å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼ã€‚")
                            
                    except Exception as e:
                        st.error(f"åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                        st.exception(e)
        
        except Exception as e:
            st.error(f"æ•°æ®è¯»å–é”™è¯¯: {str(e)}")
            st.info("è¯·ç¡®ä¿ä¸Šä¼ çš„æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼Œå¹¶åŒ…å«å¿…è¦çš„å­—æ®µã€‚")
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.matching_complete and st.session_state.analysis is not None:
        st.markdown("---")
        st.markdown('<h2 class="sub-header">ğŸ“Š åŒ¹é…åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
        
        analysis = st.session_state.analysis
        
        # 1. æ¦‚è§ˆæŒ‡æ ‡
        analysis.create_summary_metrics()
        
        # 2. å¤´å¯¸æ±‡æ€»è¡¨ï¼ˆå¼€ä»“/å¹³ä»“åŠ æƒå‡ä»·ï¼‰
        if show_positions:
            st.markdown('<h3 class="sub-header">âš–ï¸ å¤´å¯¸æ±‡æ€»ä¸åŠ æƒå¹³å‡ä»·æ ¼</h3>', unsafe_allow_html=True)
            analysis.create_position_summary_table()
        
        # 3. åŒ¹é…æ˜ç»†è¡¨
        st.markdown('<h3 class="sub-header">ğŸ“‹ åŒ¹é…æ˜ç»†è¡¨</h3>', unsafe_allow_html=True)
        
        # æ·»åŠ ç­›é€‰å™¨
        col1, col2 = st.columns(2)
        with col1:
            position_filter = st.selectbox(
                "å¤´å¯¸ç±»å‹ç­›é€‰",
                ["å…¨éƒ¨", "å¼€ä»“", "å¹³ä»“"],
                index=0
            )
        
        with col2:
            commodity_filter = st.multiselect(
                "å•†å“ç­›é€‰",
                options=analysis.df_relations['Commodity'].unique() if 'Commodity' in analysis.df_relations.columns else [],
                default=analysis.df_relations['Commodity'].unique() if 'Commodity' in analysis.df_relations.columns else []
            )
        
        # åº”ç”¨ç­›é€‰
        filtered_df = analysis.df_relations.copy()
        if position_filter != "å…¨éƒ¨":
            filtered_df = filtered_df[filtered_df['Position_Type'] == position_filter]
        
        if commodity_filter:
            filtered_df = filtered_df[filtered_df['Commodity'].isin(commodity_filter)]
        
        # æ˜¾ç¤ºç­›é€‰åçš„æ•°æ®
        st.dataframe(filtered_df.head(max_rows), use_container_width=True)
        st.caption(f"æ˜¾ç¤º {len(filtered_df.head(max_rows))} æ¡è®°å½•ï¼Œå…± {len(filtered_df)} æ¡åŒ¹é…è®°å½• (ç­›é€‰å)")
        
        # 4. åˆ†æå›¾è¡¨
        if show_charts and not analysis.df_relations.empty:
            st.markdown('<h3 class="sub-header">ğŸ“ˆ å¯è§†åŒ–åˆ†æ</h3>', unsafe_allow_html=True)
            
            # å›¾è¡¨é€‰é¡¹å¡
            tab1, tab2 = st.tabs([
                "ğŸ“Š åŒ¹é…é‡åˆ†æ", "ğŸ’° P/Låˆ†æ"
            ])
            
            with tab1:
                fig1 = analysis.create_match_volume_chart()
                if fig1:
                    st.plotly_chart(fig1, use_container_width=True)
                else:
                    st.info("æ— åŒ¹é…é‡æ•°æ®")
            
            with tab2:
                # P/Låˆ†æ
                if not analysis.df_relations.empty and 'Alloc_Total_PL' in analysis.df_relations.columns:
                    fig = make_subplots(
                        rows=1, cols=2,
                        subplot_titles=('ğŸ’° P/Låˆ†å¸ƒ', 'ğŸ“Š P/LæŒ‰å¤´å¯¸ç±»å‹'),
                        specs=[[{"type": "histogram"}, {"type": "pie"}]]
                    )
                    
                    # P/Lç›´æ–¹å›¾
                    fig.add_trace(
                        go.Histogram(x=analysis.df_relations['Alloc_Total_PL'], nbinsx=30,
                                    name='P/Låˆ†å¸ƒ'),
                        row=1, col=1
                    )
                    fig.add_vline(x=0, line_dash="dash", line_color="red", row=1, col=1)
                    
                    # P/LæŒ‰å¤´å¯¸ç±»å‹
                    if 'Position_Type' in analysis.df_relations.columns:
                        pl_by_type = analysis.df_relations.groupby('Position_Type')['Alloc_Total_PL'].sum().reset_index()
                        fig.add_trace(
                            go.Pie(labels=pl_by_type['Position_Type'], 
                                  values=pl_by_type['Alloc_Total_PL'],
                                  name='P/LæŒ‰ç±»å‹'),
                            row=1, col=2
                        )
                    
                    fig.update_layout(height=400)
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("æ— P/Læ•°æ®")
        
        # 5. æ•°æ®å¯¼å‡º
        st.markdown("---")
        st.markdown('<h3 class="sub-header">ğŸ’¾ æ•°æ®å¯¼å‡º</h3>', unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            # å¯¼å‡ºåŒ¹é…ç»“æœ
            if not analysis.df_relations.empty:
                csv_data = analysis.df_relations.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="ğŸ“¥ åŒ¹é…ç»“æœ",
                    data=csv_data,
                    file_name=f"hedge_matching_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col2:
            # å¯¼å‡ºå¼€ä»“æ±‡æ€»
            if analysis.open_summary is not None and not analysis.open_summary.empty:
                open_csv = analysis.open_summary.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="âš–ï¸ å¼€ä»“æ±‡æ€»",
                    data=open_csv,
                    file_name=f"open_positions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col3:
            # å¯¼å‡ºå¹³ä»“æ±‡æ€»
            if analysis.close_summary is not None and not analysis.close_summary.empty:
                close_csv = analysis.close_summary.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="âš–ï¸ å¹³ä»“æ±‡æ€»",
                    data=close_csv,
                    file_name=f"close_positions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col4:
            # å¯¼å‡ºæ‰€æœ‰æ•°æ®
            @st.cache_data
            def convert_to_excel(df_dict):
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    for sheet_name, df in df_dict.items():
                        if df is not None and not df.empty:
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                return output.getvalue()
            
            if analysis.df_relations is not None:
                excel_data = convert_to_excel({
                    "åŒ¹é…ç»“æœ": analysis.df_relations,
                    "å¼€ä»“æ±‡æ€»": analysis.open_summary if analysis.open_summary is not None else pd.DataFrame(),
                    "å¹³ä»“æ±‡æ€»": analysis.close_summary if analysis.close_summary is not None else pd.DataFrame(),
                    "å®è´§æ•°æ®": analysis.df_physical,
                    "çº¸è´§å‡€ä»“": analysis.df_paper_net
                })
                
                st.download_button(
                    label="ğŸ“Š å®Œæ•´æ•°æ®",
                    data=excel_data,
                    file_name=f"hedge_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
    
    else:
        # æ¬¢è¿é¡µé¢
        if not (paper_file and physical_file):
            st.markdown("---")
            st.markdown('<div class="info-box">ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ çº¸è´§å’Œå®è´§æ•°æ®æ–‡ä»¶å¼€å§‹åˆ†æ</div>', unsafe_allow_html=True)
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                st.markdown("""
                ### ğŸ¯ ç³»ç»Ÿå·¥ä½œæµç¨‹ (v2.0)
                
                1. **æ•°æ®ä¸Šä¼ **
                   - çº¸è´§äº¤æ˜“æ•°æ® (åŒ…å«äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡ã€å•†å“ã€ä»·æ ¼ç­‰)
                   - å®è´§æŒä»“æ•°æ® (åŒ…å«Cargo_IDã€äº¤æ˜“é‡ã€å¥—ä¿ä»£ç†ã€ç›®æ ‡æœˆä»½ç­‰)
                
                2. **æ™ºèƒ½åŒ¹é… (æŒ‰æ–°è§„åˆ™)**
                   - **æ—¶é—´è¿‡æ»¤**: ä»…åŒ¹é…æŒ‡å®šæ—¥æœŸ(11æœˆ12æ—¥)ä¹‹åçš„çº¸è´§äº¤æ˜“
                   - **ä¼˜å…ˆçº§1**: BRENTè®¡ä»·å“ç§ä¼˜å…ˆï¼ŒJCCæ¬¡ä¹‹
                   - **ä¼˜å…ˆçº§2**: å®è´§æŒ‰ phy-2026-04 â†’ 05 â†’ 01 â†’ 02 â†’ 03 é¡ºåºåŒ¹é…
                   - **å¤´å¯¸åŒºåˆ†**: æ­£æ•°ä¸ºå¼€ä»“ï¼Œè´Ÿæ•°ä¸ºå¹³ä»“
                
                3. **åŠ æƒå‡ä»·è®¡ç®—**
                   - **å¼€ä»“å‡ä»·**: æŒ‰å•†å“å’Œæœˆä»½è®¡ç®—åŠ æƒå¹³å‡å¼€ä»“ä»·æ ¼
                   - **å¹³ä»“å‡ä»·**: æŒ‰å•†å“å’Œæœˆä»½è®¡ç®—åŠ æƒå¹³å‡å¹³ä»“ä»·æ ¼
                   - **æœ‰æ•ˆæ€§æµ‹è¯•**: ä¸ºå¥—ä¿æœ‰æ•ˆæ€§æµ‹è¯•æä¾›åŸºç¡€æ•°æ®
                
                4. **æ•°æ®å¯¼å‡º**
                   - åŒ¹é…ç»“æœCSV
                   - å¼€ä»“/å¹³ä»“æ±‡æ€»CSV
                   - å®Œæ•´æ•°æ®Excel
                """)
            
            with col2:
                st.markdown("""
                ### ğŸ“‹ æ•°æ®è¦æ±‚
                
                **çº¸è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Trade Date`: äº¤æ˜“æ—¥æœŸ
                - `Volume`: äº¤æ˜“é‡ (æ­£ä¹°è´Ÿå–)
                - `Commodity`: å•†å“å“ç§
                - `Month`: åˆçº¦æœˆä»½ (å¯é€‰)
                - `Price`: äº¤æ˜“ä»·æ ¼ (æ¨è)
                
                **å®è´§æ•°æ®å¿…éœ€å­—æ®µ:**
                - `Cargo_ID`: å®è´§ç¼–å· (å»ºè®®åŒ…å«å¹´ä»½æœˆä»½)
                - `Volume`: äº¤æ˜“é‡
                - `Hedge_Proxy`: å¥—ä¿ä»£ç† (å¦‚BRENT, JCC)
                - `Target_Contract_Month`: ç›®æ ‡æœˆä»½
                
                **åŒ¹é…è§„åˆ™:**
                - ä»…åŒ¹é…æŒ‡å®šæ—¥æœŸä¹‹åçš„äº¤æ˜“
                - BRENTä¼˜å…ˆäºJCC
                - ç‰¹å®šCargo_IDä¼˜å…ˆé¡ºåº
                - è‡ªåŠ¨è®¡ç®—åŠ æƒå‡ä»·
                """)
            
            st.markdown("---")
            
            # ç¤ºä¾‹æ•°æ®å±•ç¤º
            with st.expander("ğŸ“š æŸ¥çœ‹æ•°æ®æ ¼å¼ç¤ºä¾‹"):
                example_tab1, example_tab2 = st.tabs(["çº¸è´§ç¤ºä¾‹", "å®è´§ç¤ºä¾‹"])
                
                with example_tab1:
                    example_paper = pd.DataFrame({
                        'Trade Date': ['2024-11-12', '2024-11-13', '2024-11-14', '2024-11-10'],
                        'Volume': [1000, -500, 2000, 1500],
                        'Commodity': ['BRENT', 'BRENT', 'JCC', 'BRENT'],
                        'Month': ['JAN 25', 'JAN 25', 'FEB 25', 'DEC 24'],
                        'Price': [75.50, 76.20, 74.80, 74.00],
                        'Recap No': ['TKT-001', 'TKT-002', 'TKT-003', 'TKT-004']
                    })
                    st.dataframe(example_paper, use_container_width=True)
                    st.caption("æ³¨æ„: 2024-11-10çš„äº¤æ˜“åœ¨æŒ‡å®šæ—¥æœŸä¹‹å‰ï¼Œä¸ä¼šè¢«åŒ¹é…")
                
                with example_tab2:
                    example_physical = pd.DataFrame({
                        'Cargo_ID': ['PHY-2026-04-001', 'PHY-2026-05-001', 'PHY-2026-01-001'],
                        'Volume': [500000, 300000, 400000],
                        'Hedge_Proxy': ['BRENT', 'JCC', 'BRENT'],
                        'Target_Contract_Month': ['JAN 25', 'FEB 25', 'JAN 25'],
                        'Direction': ['Buy', 'Buy', 'Sell'],
                        'Designation_Date': ['2024-11-12', '2024-11-12', '2024-11-12']
                    })
                    st.dataframe(example_physical, use_container_width=True)
                    st.caption("æ³¨æ„: PHY-2026-04ä¼˜å…ˆäºPHY-2026-05ï¼ŒPHY-2026-05ä¼˜å…ˆäºPHY-2026-01")

if __name__ == "__main__":
    main()